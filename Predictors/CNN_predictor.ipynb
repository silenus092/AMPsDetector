{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.3\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ubuntu/miniconda3/envs/py3\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ipython-7.20.0             |   py37h888b3d9_2         1.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.1 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi            pkgs/main::certifi-2020.12.5-py37h06a~ --> conda-forge::certifi-2020.12.5-py37h89c1867_1\n",
      "  ipython                             7.12.0-py37h5ca1d4c_0 --> 7.20.0-py37h888b3d9_2\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.1.19-~ --> conda-forge::ca-certificates-2020.12.5-ha878542_0\n",
      "  keras                            pkgs/main::keras-2.3.1-0 --> conda-forge::keras-2.3.1-py37_0\n",
      "  openssl              pkgs/main::openssl-1.1.1i-h27cfd23_0 --> conda-forge::openssl-1.1.1i-h7f98852_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ipython-7.20.0       | 1.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install -c conda-forge keras==2.3.1 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r_WHUIJomX5u",
    "outputId": "968d231a-48ea-48f5-ffa9-9ed6ccbae282"
   },
   "outputs": [],
   "source": [
    "\n",
    "# for keras 2.3.1\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toPredictDF(path,to_dir,existing_result):\n",
    "    appended_pkl = []\n",
    "    for infile in glob.glob(path):\n",
    "        #print(\"Read:\",infile)\n",
    "        file_name = os.path.basename(infile)\n",
    "        result_path=to_dir+\"/\"+file_name.replace(\"pkl\", \"ML.pkl\")\n",
    "        if result_path in existing_result :\n",
    "        # print(\"found then skip : \" , result)\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_pickle(infile)\n",
    "            ready_df =df[[ \"reps\"]]\n",
    "            df_new = ready_df.reps.apply(pd.Series).astype(np.float64)\n",
    "            df_new.columns = df_new.columns.astype(str)\n",
    "            dl = learner.dls.test_dl(df_new)\n",
    "            _preds,_none ,_y = learner.get_preds(dl=dl, with_decoded=True)\n",
    "            df.drop(columns=['reps','length'],inplace =True)\n",
    "            df['class'] = _y\n",
    "            #print(\"Save:\",result_path)\n",
    "            df.to_pickle(result_path)\n",
    "    print(\"Complete\")\n",
    "\n",
    "def mergeDF(path,to_dir,file_name):\n",
    "    appended_data = []\n",
    "    for infile in glob.glob(path):\n",
    "        #print(infile)\n",
    "        data = pd.read_pickle(infile)\n",
    "        # store DataFrame in list\n",
    "        appended_data.append(data)\n",
    "    result_path=to_dir+\"/\"+file_name\n",
    "    print(\"Save:\",result_path)\n",
    "    appended_data = pd.concat(appended_data)\n",
    "    appended_data.sort_values(by=['ID'], inplace=True)\n",
    "    appended_data.to_pickle(result_path)\n",
    "    return appended_data\n",
    "\n",
    "def predict_CNN(path,to_dir,existing_result):\n",
    "    appended_pkl = []\n",
    "    for infile in glob.glob(path):  \n",
    "     #print(\"Read:\",infile)\n",
    "        file_name = os.path.basename(infile)\n",
    "        result_path=to_dir+\"/\"+file_name.replace(\"pkl\", \"ML.pkl\")\n",
    "        if result_path in existing_result :\n",
    "        # print(\"found then skip : \" , result)\n",
    "            continue\n",
    "        else:\n",
    "            df = pd.read_pickle(infile)\n",
    "            ready_df =df[[ \"reps\"]]\n",
    "            \n",
    "            X= np.array(df['reps'].to_list())\n",
    "            X_test = np.reshape(X,(X.shape[0],X.shape[1],1))\n",
    "            y_probas = learner.predict(X_test)\n",
    "            threshold = 0.5\n",
    "            _y = np.where(y_probas > threshold, 1, 0)\n",
    "            df.drop(columns=['reps'],inplace =True)\n",
    "            df['class'] = _y\n",
    "            #print(\"Save:\",result_path)\n",
    "            df.to_pickle(result_path) \n",
    "\n",
    "    print(\"Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZascbWaBmX6K"
   },
   "outputs": [],
   "source": [
    "# load the baseline model\n",
    "#learn.load('TubularLearner.fastAI._stage1')\n",
    "deployed_path = \"/mnt/vdb/thesis/CustomCNN.Adam.512_1211.hdf5\"\n",
    "#deployed_path = \"TubularLearner.fastAI._stage2.pth\"\n",
    "#learner = load_model(deployed_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    \n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "#with tf.device('/cpu:0'):\n",
    "learner = load_model(deployed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1900, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1900, 512)         4608      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 633, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 633, 256)          524544    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 316, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 80896)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1211)              97966267  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1211)              1467732   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 1212      \n",
      "=================================================================\n",
      "Total params: 99,964,363\n",
      "Trainable params: 99,964,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summarize model.\n",
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECockRoach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "existing_result = []\n",
    "for infile in glob.glob(\"/mnt/vdb/DECockroach/cd100/result_2_CNN_Adam/*.pkl\"):\n",
    "    # print(infile)\n",
    "    existing_result.append(infile)\n",
    "print(len(existing_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predict_CNN(\"/mnt/vdb/DECockroach/cd100/reps/*.pkl\",\"/mnt/vdb/DECockroach/cd100/result_2_CNN_Adam\",existing_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write result\n",
    "result_df =mergeDF(\"/mnt/vdb/DECockroach/cd100/result_2_CNN_Adam/*.pkl\",\"/mnt/vdb/DECockroach/cd100/result_2_CNN_Adam\",\"DECockroach.len15.MLResult.plk\")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[result_df[\"class\"]== 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoTrGO6HmX6E"
   },
   "outputs": [],
   "source": [
    "existing_result = []\n",
    "for infile in glob.glob(\"/mnt/vdb/Bat/cd100/result_2_CNN_Adam/*.pkl\"):\n",
    "    # print(infile)\n",
    "    existing_result.append(infile)\n",
    "print(len(existing_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predict_CNN(\"/mnt/vdb/Bat/cd100/reps/*.pkl\",\"/mnt/vdb/Bat/cd100/result_2_CNN_Adam\",existing_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write result\n",
    "result_df =mergeDF(\"/mnt/vdb/Bat/cd100/result_2_CNN_Adam/*.pkl\",\"/mnt/vdb/Bat/cd100/result_2_CNN_Adam\",\"Bat.len10.MLResult.plk\")\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "FASTAI_predictor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
