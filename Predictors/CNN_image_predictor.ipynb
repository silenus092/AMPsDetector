{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "suspected-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "creative-reliance",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# load  DECockroach \\n\\ndf_ = pd.read_csv(\\'../VerifyAMPs/TransPi/truth_no_ambiguous/DECockroach_truth_set.csv\\', header=0)\\n\\nfrom_path = \\'/mnt/vdb/DECockroach/pws/transpi/images/normal/NonAMP\\'\\nto_path = \\'/mnt/vdb/DECockroach/pws/transpi/images/normal/AMP\\'\\ncheck_ = []\\nfor index, row in df_.iterrows():\\n    filename = row[\"prot_id\"] + \".png\" \\n    Path(os.path.join(from_path, filename)).rename(os.path.join(to_path, filename))\\n    check_.append(os.path.join(to_path, filename))\\nprint(len(check_)) #236'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Move file\n",
    "\"\"\"\n",
    "\n",
    "# load  BAT  (stringent)\n",
    "df_ = pd.read_csv('../VerifyAMPs/TransPi/truth_no_ambiguous/BAT_truth_set.stringent.csv', header=0)\n",
    "from_path = '/mnt/vdb/Bat/pws/transpi/images/stringent/NonAMP'\n",
    "to_path = '/mnt/vdb/Bat/pws/transpi/images/stringent/AMP'\n",
    "check_ = []\n",
    "for index, row in df_.iterrows():\n",
    "    filename = row[\"prot_id\"] + \".png\" \n",
    "    Path(os.path.join(from_path, filename)).rename(os.path.join(to_path, filename))\n",
    "    check_.append(os.path.join(to_path, filename))\n",
    "# 235 \n",
    "print(len(check_))\n",
    "\n",
    "\n",
    "# load  BAT  \n",
    "df_ = pd.read_csv('../VerifyAMPs/TransPi/truth_no_ambiguous/BAT_truth_set.csv', header=0)\n",
    "from_path = '/mnt/vdb/Bat/pws/transpi/images/normal/NonAMP'\n",
    "to_path = '/mnt/vdb/Bat/pws/transpi/images/normal/AMP'\n",
    "check_ = []\n",
    "for index, row in df_.iterrows():\n",
    "        filename = row[\"prot_id\"] + \".png\" \n",
    "        Path(os.path.join(from_path, filename)).rename(os.path.join(to_path, filename))\n",
    "        check_.append(os.path.join(to_path, filename))\n",
    "print(len(check_)) #356\n",
    "\"\"\"\n",
    "\n",
    "# load  DECockroach *(stringent)\n",
    "df_ = pd.read_csv('../VerifyAMPs/TransPi/truth_no_ambiguous/DECockroach_truth_set.stringent.csv', header=0)\n",
    "\n",
    "from_path = '/mnt/vdb/DECockroach/pws/transpi/images/stringent/NonAMP'\n",
    "to_path = '/mnt/vdb/DECockroach/pws/transpi/images/stringent/AMP'\n",
    "check_ = []\n",
    "for index, row in df_.iterrows():\n",
    "    filename = row[\"prot_id\"] + \".png\" \n",
    "    Path(os.path.join(from_path, filename)).rename(os.path.join(to_path, filename))\n",
    "    check_.append(os.path.join(to_path, filename))\n",
    "    # 138\n",
    "print(len(check_))\n",
    "\n",
    "\"\"\"\n",
    "# load  DECockroach \n",
    "\n",
    "df_ = pd.read_csv('../VerifyAMPs/TransPi/truth_no_ambiguous/DECockroach_truth_set.csv', header=0)\n",
    "\n",
    "from_path = '/mnt/vdb/DECockroach/pws/transpi/images/normal/NonAMP'\n",
    "to_path = '/mnt/vdb/DECockroach/pws/transpi/images/normal/AMP'\n",
    "check_ = []\n",
    "for index, row in df_.iterrows():\n",
    "    filename = row[\"prot_id\"] + \".png\" \n",
    "    Path(os.path.join(from_path, filename)).rename(os.path.join(to_path, filename))\n",
    "    check_.append(os.path.join(to_path, filename))\n",
    "print(len(check_)) #236\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "subsequent-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model \n",
    "deployed_path = \"/mnt/vdb/thesis/CustomCNN.Adam.image.training2.set_9.h5\"\n",
    "#deployed_path = \"/mnt/vdb/thesis/CustomCNN.Adam.image.training2.set_9.nonscale.h5\"\n",
    "import tensorflow as tf\n",
    "\n",
    "#with tf.device('/cpu:0'):\n",
    "learner = load_model(deployed_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-laptop",
   "metadata": {},
   "source": [
    "The order of the files that populate file_list, is the same order X_test appears in, by row.\n",
    "\n",
    "So just match the indices to correlate filename with prediction.\n",
    "\n",
    "X_test[0] ~ prediction[0] ~ file_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "harmful-montana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 images belonging to 1 classes.\n",
      "Found 10180 images belonging to 2 classes.\n",
      "Found 10189 images belonging to 2 classes.\n",
      "Found 15424 images belonging to 2 classes.\n",
      "Found 15424 images belonging to 2 classes.\n",
      "{'AMP': 0}\n",
      "{'AMP': 0, 'NonAMP': 1}\n",
      "{'AMP': 0, 'NonAMP': 1}\n",
      "{'AMP': 0, 'NonAMP': 1}\n",
      "{'AMP': 0, 'NonAMP': 1}\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(validation_split=0.2,rescale=1./255)\n",
    "\n",
    "\n",
    "truth_set = datagen.flow_from_directory(directory='../datasets/truthset/images/',\n",
    "                                        class_mode='binary', batch_size=128,target_size=(200, 200),shuffle= False)\n",
    "\n",
    "Bat_data = datagen.flow_from_directory(directory='/mnt/vdb/Bat/pws/transpi/images/normal',\n",
    "                                      class_mode='binary', batch_size=128, target_size=(200, 200),shuffle= False)\n",
    "\n",
    "Bat_stringent_data = datagen.flow_from_directory(directory='/mnt/vdb/Bat/pws/transpi/images/stringent',\n",
    "                                        class_mode='binary', batch_size=128,target_size=(200, 200),\n",
    "                                        shuffle= False)\n",
    "\n",
    "DECockroach_data = datagen.flow_from_directory(directory='/mnt/vdb/DECockroach/pws/transpi/images/normal',\n",
    "                                        class_mode='binary', batch_size=128,target_size=(200, 200),shuffle= False)\n",
    "\n",
    "DECockroach_stringent_data = datagen.flow_from_directory(directory='/mnt/vdb/DECockroach/pws/transpi/images/stringent',\n",
    "                                        class_mode='binary', batch_size=128,target_size=(200, 200),shuffle= False)\n",
    "print(truth_set.class_indices)\n",
    "print(Bat_data.class_indices)\n",
    "print(Bat_stringent_data.class_indices)\n",
    "print(DECockroach_data.class_indices)\n",
    "print(DECockroach_stringent_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aware-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 images belonging to 1 classes.\n",
      "{'AMP': 0}\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(validation_split=0.2, rescale=1/255  )\n",
    "\n",
    "\n",
    "truth_set = datagen.flow_from_directory(directory='../datasets/truthset/images/',\n",
    "                                        class_mode='binary', batch_size=128,target_size=(200, 200),shuffle= False)\n",
    "print(truth_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "immune-helmet",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_truth_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b85e96c80250>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## test_truth_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_truth_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_truth_data' is not defined"
     ]
    }
   ],
   "source": [
    "## test_truth_data\n",
    "yhat = learner.predict_generator(test_truth_data)\n",
    "_y = np.where(yhat > 0.5, 1, 0)\n",
    "len(_y[_y ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cathedral-model",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_truth_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1d7e5a3a5286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_truth_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_truth_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_truth_data' is not defined"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image, label = test_truth_data._get_batches_of_transformed_samples(np.array([index]))\n",
    "image_name = test_truth_data.filenames[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "welcome-correlation",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e93e7f15fbc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image_name' is not defined"
     ]
    }
   ],
   "source": [
    "image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-flashing",
   "metadata": {},
   "source": [
    "# New Groud Truthset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "million-mobile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AMP/.ipynb_checkpoints/Defensin_g14-checkpoint.png'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_set.filenames.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "typical-tulsa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = truth_set.classes\n",
    "y_probas = learner.predict_generator(generator=truth_set)\n",
    "y_pred = np.where(y_probas >= 0.5, 1, 0)\n",
    "len(y_pred[y_pred == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statutory-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old method  , new threshold 53 ?? how come\n",
    "len(y_pred[y_pred == 0]) # 49/62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alert-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "celtic-rebate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas = learner.predict_generator(generator=truth_set)\n",
    "y_pred = np.where(y_probas >= 0.5, 1, 0)\n",
    "len(y_pred[y_pred == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "protective-composite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold 0.26\n",
    "y_probas = learner.predict_generator(generator=truth_set)\n",
    "y_pred = np.where(y_probas >= 0.26, 1, 0)\n",
    "len(y_pred[y_pred == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thirty-perception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = truth_set.classes\n",
    "y_probas = learner.predict_generator(generator=truth_set)\n",
    "y_pred = np.where(y_probas >= 0.5, 1, 0)\n",
    "len(y_pred[y_pred == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mexican-petite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.where(y_probas >= 0.4, 1, 0)\n",
    "len(y_pred[y_pred == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-burden",
   "metadata": {},
   "source": [
    "# SET 9 Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-franchise",
   "metadata": {},
   "source": [
    "# BAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rocky-intermediate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.38      0.06       356\n",
      "           1       0.96      0.57      0.71      9824\n",
      "\n",
      "    accuracy                           0.56     10180\n",
      "   macro avg       0.50      0.47      0.38     10180\n",
      "weighted avg       0.93      0.56      0.69     10180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = Bat_data.classes\n",
    "y_probas = learner.predict_generator(generator=Bat_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "measured-scotland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMP_list = y_pred[0:356]\n",
    "len(AMP_list[AMP_list ==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "governing-health",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8663"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonAMP_list = y_pred[356:]\n",
    "len(nonAMP_list[nonAMP_list ==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-penny",
   "metadata": {},
   "source": [
    "### stringent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "romance-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.06      0.04       235\n",
      "           1       0.98      0.95      0.96      9954\n",
      "\n",
      "    accuracy                           0.93     10189\n",
      "   macro avg       0.50      0.51      0.50     10189\n",
      "weighted avg       0.96      0.93      0.94     10189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = Bat_stringent_data.classes\n",
    "y_probas = learner.predict_generator(generator=Bat_stringent_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "traditional-assurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n"
     ]
    }
   ],
   "source": [
    "#AMP_list = y_pred[0:235]\n",
    "print(len(y_pred[y_pred ==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "everyday-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9697\n"
     ]
    }
   ],
   "source": [
    "#nonAMP_list = y_pred[235:]\n",
    "print(len(y_pred[y_pred  ==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "certain-nurse",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 20, 61, 66, 113, 164, 175, 200, 201, 208, 215, 229]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consensus\n",
    "\n",
    "with open('../VerifyAMPs/TransPi/consensus/bat.final.truth') as f:\n",
    "    bat_lines = [line.rstrip() for line in f]\n",
    "# get index  inside list \n",
    "_truth_index = []\n",
    "for i in bat_lines:\n",
    "    search = \"AMP/\"+ i +\".png\"\n",
    "    index = Bat_stringent_data.filenames.index(search)\n",
    "    _truth_index.append(index)\n",
    "_truth_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exciting-wrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[[4, 8, 20, 61, 66, 113, 164, 175, 200, 201, 208, 215, 229]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "terminal-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold -0.26\n",
    "y_pred = np.where(y_probas >= 0.26, 1, 0)\n",
    "#print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "swedish-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4414\n",
      "5775\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred[y_pred ==0]))\n",
    "print(len(y_pred[y_pred ==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brief-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truthset\n",
    "y_pred[[4, 8, 20, 61, 66, 113, 164, 175, 200, 201, 208, 215, 229]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "metallic-respondent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.06      0.04       235\n",
      "           1       0.98      0.95      0.96      9954\n",
      "\n",
      "    accuracy                           0.93     10189\n",
      "   macro avg       0.50      0.51      0.50     10189\n",
      "weighted avg       0.96      0.93      0.94     10189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = Bat_stringent_data.classes\n",
    "y_probas = learner.predict_generator(generator=Bat_stringent_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "metropolitan-while",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "9697\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred[y_pred ==0]))\n",
    "print(len(y_pred[y_pred ==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "advised-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[[4, 8, 20, 61, 66, 113, 164, 175, 200, 201, 208, 215, 229]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-apollo",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ordered-missouri",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n",
      "9827\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.where(y_probas >= 0.26, 1, 0)\n",
    "print(len(y_pred[y_pred ==0]))\n",
    "print(len(y_pred[y_pred ==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "legitimate-labor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[[4, 8, 20, 61, 66, 113, 164, 175, 200, 201, 208, 215, 229]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-classic",
   "metadata": {},
   "source": [
    "# DECockroach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "detected-hybrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.11      0.03       236\n",
      "           1       0.98      0.90      0.94     15188\n",
      "\n",
      "    accuracy                           0.88     15424\n",
      "   macro avg       0.50      0.50      0.48     15424\n",
      "weighted avg       0.97      0.88      0.92     15424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = DECockroach_data.classes\n",
    "y_probas = learner.predict_generator(generator=DECockroach_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "serious-coverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMP_list = y_pred[0:236]\n",
    "len(AMP_list[AMP_list ==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "plastic-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13619"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonAMP_list = y_pred[236:]\n",
    "len(nonAMP_list[nonAMP_list ==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-bridal",
   "metadata": {},
   "source": [
    "### stringent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "color-richmond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.07      0.02       138\n",
      "           1       0.99      0.95      0.97     15286\n",
      "\n",
      "    accuracy                           0.94     15424\n",
      "   macro avg       0.50      0.51      0.49     15424\n",
      "weighted avg       0.98      0.94      0.96     15424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = DECockroach_stringent_data.classes\n",
    "y_probas = learner.predict_generator(generator=DECockroach_stringent_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "extensive-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796\n"
     ]
    }
   ],
   "source": [
    "#AMP_list = y_pred[0:138]\n",
    "print(len(y_pred[y_pred ==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acquired-narrative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14628\n"
     ]
    }
   ],
   "source": [
    "#nonAMP_list = y_pred[138:]\n",
    "print(len(y_pred[y_pred ==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "accepting-bikini",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 14, 15, 16, 18, 32, 34, 47, 53, 65, 74, 78, 81, 82, 86, 104, 111, 117, 129]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../VerifyAMPs/TransPi/consensus/DECockroach.final') as f:\n",
    "    de_lines = [line.rstrip() for line in f]\n",
    "# get index  inside list \n",
    "_truth_index = []\n",
    "for i in de_lines:\n",
    "    search = \"AMP/\"+ i +\".png\"\n",
    "    index = DECockroach_stringent_data.filenames.index(search)\n",
    "    _truth_index.append(index)\n",
    "_truth_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "differential-exchange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[[5, 14, 15, 16, 18, 32, 34, 47, 53, 65, 74, 78, 81, 82, 86, 104, 111, 117, 129]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "incoming-extension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.07      0.02       138\n",
      "           1       0.99      0.95      0.97     15286\n",
      "\n",
      "    accuracy                           0.94     15424\n",
      "   macro avg       0.50      0.51      0.49     15424\n",
      "weighted avg       0.98      0.94      0.96     15424\n",
      "\n",
      "14628\n",
      "796\n"
     ]
    }
   ],
   "source": [
    "y_test = DECockroach_stringent_data.classes\n",
    "y_probas = learner.predict_generator(generator=DECockroach_stringent_data)\n",
    "y_pred = np.where(y_probas >= 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(len(y_pred[y_pred ==1]))\n",
    "print(len(y_pred[y_pred ==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "empirical-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[[5, 14, 15, 16, 18, 32, 34, 47, 53, 65, 74, 78, 81, 82, 86, 104, 111, 117, 129]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-cooper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "weighted-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.07      0.02       138\n",
      "           1       0.99      0.96      0.98     15286\n",
      "\n",
      "    accuracy                           0.95     15424\n",
      "   macro avg       0.50      0.51      0.50     15424\n",
      "weighted avg       0.98      0.95      0.97     15424\n",
      "\n",
      "14831\n",
      "593\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.where(y_probas >= 0.26, 1, 0)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(len(y_pred[y_pred ==1]))\n",
    "print(len(y_pred[y_pred ==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "neural-module",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[[5, 14, 15, 16, 18, 32, 34, 47, 53, 65, 74, 78, 81, 82, 86, 104, 111, 117, 129]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-toolbox",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-point",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "restricted-conjunction",
   "metadata": {},
   "source": [
    "# SET 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-binding",
   "metadata": {},
   "source": [
    "## BAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "suffering-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.38      0.06       356\n",
      "           1       0.96      0.57      0.71      9824\n",
      "\n",
      "    accuracy                           0.56     10180\n",
      "   macro avg       0.50      0.47      0.38     10180\n",
      "weighted avg       0.93      0.56      0.69     10180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = Bat_data.classes\n",
    "y_probas = learner.predict_generator(generator=Bat_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wanted-flower",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.41      0.04       235\n",
      "           1       0.98      0.57      0.72      9954\n",
      "\n",
      "    accuracy                           0.56     10189\n",
      "   macro avg       0.50      0.49      0.38     10189\n",
      "weighted avg       0.95      0.56      0.70     10189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = Bat_stringent_data.classes\n",
    "y_probas = learner.predict_generator(generator=Bat_stringent_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dominican-delight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consensus\n",
    "\n",
    "with open('../VerifyAMPs/TransPi/consensus/bat.final.truth') as f:\n",
    "    bat_lines = [line.rstrip() for line in f]\n",
    "# get index  inside list \n",
    "_truth_index = []\n",
    "for i in bat_lines:\n",
    "    search = \"AMP/\"+ i +\".png\"\n",
    "    index = Bat_stringent_data.filenames.index(search)\n",
    "    _truth_index.append(index)\n",
    "y_pred[_truth_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-marketplace",
   "metadata": {},
   "source": [
    "## DE Cockraoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "appointed-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.47      0.03       236\n",
      "           1       0.98      0.49      0.65     15188\n",
      "\n",
      "    accuracy                           0.49     15424\n",
      "   macro avg       0.50      0.48      0.34     15424\n",
      "weighted avg       0.97      0.49      0.64     15424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = DECockroach_data.classes\n",
    "y_probas = learner.predict_generator(generator=DECockroach_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "seven-mathematics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.46      0.02       138\n",
      "           1       0.99      0.49      0.66     15286\n",
      "\n",
      "    accuracy                           0.49     15424\n",
      "   macro avg       0.50      0.48      0.34     15424\n",
      "weighted avg       0.98      0.49      0.65     15424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = DECockroach_stringent_data.classes\n",
    "y_probas = learner.predict_generator(generator=DECockroach_stringent_data)\n",
    "y_pred = np.where(y_probas > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "specified-tsunami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../VerifyAMPs/TransPi/consensus/DECockroach.final') as f:\n",
    "    de_lines = [line.rstrip() for line in f]\n",
    "# get index  inside list \n",
    "_truth_index = []\n",
    "for i in de_lines:\n",
    "    search = \"AMP/\"+ i +\".png\"\n",
    "    index = DECockroach_stringent_data.filenames.index(search)\n",
    "    _truth_index.append(index)\n",
    "\n",
    "y_pred[_truth_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-allowance",
   "metadata": {},
   "source": [
    "Macro F1 calculates the F1 separated by class but not using weights for the aggregation:\n",
    "\n",
    "F1class1+F1class2+⋅⋅⋅+F1classN\n",
    "\n",
    "which resuls in a bigger penalisation when your model does not perform well with the minority classes(which is exactly what you want when there is imbalance)\n",
    "\n",
    "Weighted F1 score calculates the F1 score for each class independently but when it adds them together uses a weight that depends on the number of true labels of each class:\n",
    "\n",
    "F1class1∗W1+F1class2∗W2+⋅⋅⋅+F1classN∗WN\n",
    "\n",
    "therefore favouring the majority class (which is want you usually dont want)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-constant",
   "metadata": {},
   "source": [
    "Precision : ค่าความแม่นยำ เกิดจากการนำ ค่า tp มาเทียบกับ fp\n",
    "\n",
    "Recall : ค่าความถูกต้อง เกิดจากการนำค่า tp มาเทียบกับ fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision ใน class 0 น้อย หมายความว่า FP สูง นั่นก็คือ predict จาก class 1เป็น 0 เเต่ทั้งนี้ทั้งนั้นเพราะ support 1 เยอะกว่า\n",
    "\n",
    "ส่วน recall ใน class 0 เยอะ เพราะว่า FN น้อย    ตัวที่เป็น class 0  predict เป็น 0 สะส่วนใหญ่ (ทำนายเเล้วถูกเยอะเมื่อเทียบกับค่าจริง)\n",
    "\n",
    "\n",
    "precision ใน class 1 มาก หมายความว่า FP น้อย นั้นก็คือ predict เป็น class 1 มากกว่า class 0 เเต่ก็เพราะ support เยอะกว่า\n",
    "ส่วน recall ใน class 1 น้อย เพราะว่า FN มาก ตัวที่เป็น class 1 ถูก predict เป็น 0 สะส่วนใหญ่ (ทำนายเเล้วถูกน้อยมื่อเทียบกับค่าจริง)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
