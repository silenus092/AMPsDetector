{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16429752517625420046\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8770341163598776130\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1588630576309758160\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 31595870336\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15038634741862989396\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:00:06.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZascbWaBmX6K"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "with tf.device('/cpu:0'):\n",
    "        learner= load_model(\"/mnt/vdb/thesis/ProtCNN.V5.set10.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1900, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1900, 256)    512         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1900, 256)    1024        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1900, 256)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1900, 256)    65792       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1900, 256)    1024        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1900, 256)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1900, 256)    196864      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1900, 256)    0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1900, 256)    1024        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1900, 256)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1900, 256)    65792       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1900, 256)    1024        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1900, 256)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1900, 256)    196864      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1900, 256)    0           conv1d_4[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 633, 256)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 162048)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1211)         196241339   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1211)         4844        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1211)         1467732     batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1211)         4844        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1211)         1467732     batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1211)         4844        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1211)         1467732     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1211)         4844        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1212        batch_normalization_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 201,195,043\n",
      "Trainable params: 201,183,307\n",
      "Non-trainable params: 11,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r_WHUIJomX5u",
    "outputId": "968d231a-48ea-48f5-ffa9-9ed6ccbae282"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(_df ,condition):\n",
    "    #df = _df.loc[_df.length > 30 ].copy() \n",
    "    #df = _df.loc[_df.length <= 30 ].copy()\n",
    "    if condition == 0:\n",
    "        df = _df.copy()\n",
    "    elif condition == -1 :\n",
    "        df = _df.loc[_df.length <= 30 ].copy()\n",
    "    else:\n",
    "        df = _df.loc[_df.length > condition ].copy() # select records with lenght > \n",
    "    #print(df.columns)\n",
    "    X= np.array(df['reps'].to_list())\n",
    "    X_test = np.reshape(X,(X.shape[0],X.shape[1],1))\n",
    "    y_probas = learner.predict(X_test)\n",
    "    threshold = 0.5\n",
    "    _y = np.where(y_probas > threshold, 1, 0)\n",
    "    \n",
    "    df['class'] = _y\n",
    "    #df.drop(columns=['reps'],inplace =True)\n",
    "    accuracy = (len(df[df[\"class\"] == 1])/len(df) )*100\n",
    "    #print(\"predict AMP :\"+str(len(df[df[\"class\"] == 0])))\n",
    "    #print(\"predict NonAMP:\"+str(len(df[df[\"class\"] == 1])))\n",
    "    #print(\"predict NonAMP (in percentage):\"+str(accuracy))\n",
    "    return len(df[df[\"class\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_DNN(_df ,condition):\n",
    "    #df = _df.loc[_df.length > 30 ].copy() \n",
    "    #df = _df.loc[_df.length <= 30 ].copy()\n",
    "    if condition == 0:\n",
    "        df = _df.copy()\n",
    "    elif condition == -1 :\n",
    "        df = _df.loc[_df.length <= 30 ].copy()\n",
    "    else:\n",
    "        df = _df.loc[_df.length > condition ].copy() # select records with lenght > \n",
    "    #print(df.columns)\n",
    "    X= np.array(df['reps'].to_list())\n",
    "    X_test = np.reshape(X,(X.shape[0],X.shape[1],1))\n",
    "    y_probas = learner.predict(X_test)\n",
    "    threshold = 0.5\n",
    "    _y = np.where(y_probas > threshold, 1, 0)\n",
    "    \n",
    "    df['class'] = _y\n",
    "    #df.drop(columns=['reps'],inplace =True)\n",
    "    accuracy = (len(df[df[\"class\"] == 1])/len(df) )*100\n",
    "    #print(\"predict AMP :\"+str(len(df[df[\"class\"] == 0])))\n",
    "    #print(\"predict NonAMP:\"+str(len(df[df[\"class\"] == 1])))\n",
    "    #print(\"predict NonAMP (in percentage):\"+str(accuracy))\n",
    "    return len(df[df[\"class\"] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize model.\n",
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IoTrGO6HmX6E"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_pickle(\"../datasets/truthset/AMPs_truthset.reps.plk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocpMvCNJmX6R"
   },
   "source": [
    "## Chanage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "raBn6r7zmX6T",
    "outputId": "a4c742de-63a8-4e22-fe0d-d5137e5374e6"
   },
   "outputs": [],
   "source": [
    "X= np.array(df['reps'].to_list())\n",
    "X_test = np.reshape(X,(X.shape[0],X.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "To get prediction on a new dataframe, you can use the test_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = learner.predict(X_test)\n",
    "threshold = 0.5\n",
    "_y = np.where(y_probas > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"class\"] == 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"class\"] == 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"class\"] == 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PSSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../datasets/truthset/pssm/AMPs.truthset.reps.pkl\")\n",
    "X= np.array(df['reps'].to_list())\n",
    "X_test = np.reshape(X,(X.shape[0],X.shape[1],1))\n",
    "y_probas = learner.predict(X_test)\n",
    "threshold = 0.5\n",
    "_y = np.where(y_probas > threshold, 1, 0)\n",
    "df['class'] = _y\n",
    "len(df[df[\"class\"] == 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Shuffled sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_con</th>\n",
       "      <th>&gt;200</th>\n",
       "      <th>&gt;100</th>\n",
       "      <th>&gt;70</th>\n",
       "      <th>&gt;50</th>\n",
       "      <th>&gt;30</th>\n",
       "      <th>30&lt;=</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shuff1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        no_con >200 >100  >70  >50  >30 30<=\n",
       "shuff1     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff2     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff3     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff4     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff5     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff6     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff7     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff8     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff9     NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
       "shuff10    NaN  NaN  NaN  NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame( columns=[\"no_con\",\">200\",\">100\",\">70\",\">50\",\">30\",\"30<=\"],\n",
    "    index = ['shuff1','shuff2', 'shuff3',\"shuff4\",\"shuff5\",\"shuff6\",\"shuff7\",\"shuff8\",\"shuff9\",\"shuff10\"])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProtCNN bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff1\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_42.reps.plk\")\n",
    "result_df.loc['shuff1', 'no_con']=predict(df_,0)\n",
    "result_df.loc['shuff1', '>200']= predict(df_,200)\n",
    "result_df.loc['shuff1', '>100']=predict(df_,100)\n",
    "result_df.loc['shuff1', '>70']=predict(df_,70)\n",
    "result_df.loc['shuff1', '>50']=predict(df_,50)\n",
    "result_df.loc['shuff1', '>30']=predict(df_,30)\n",
    "result_df.loc['shuff1', '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff2\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_43.reps.plk\")\n",
    "result_df.loc['shuff2', 'no_con']=predict(df_,0)\n",
    "result_df.loc['shuff2', '>200']= predict(df_,200)\n",
    "result_df.loc['shuff2', '>100']=predict(df_,100)\n",
    "result_df.loc['shuff2', '>70']=predict(df_,70)\n",
    "result_df.loc['shuff2', '>50']=predict(df_,50)\n",
    "result_df.loc['shuff2', '>30']=predict(df_,30)\n",
    "result_df.loc['shuff2', '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff3\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_44.reps.plk\")\n",
    "result_df.loc['shuff3', 'no_con']=predict(df_,0)\n",
    "result_df.loc['shuff3', '>200']= predict(df_,200)\n",
    "result_df.loc['shuff3', '>100']=predict(df_,100)\n",
    "result_df.loc['shuff3', '>70']=predict(df_,70)\n",
    "result_df.loc['shuff3', '>50']=predict(df_,50)\n",
    "result_df.loc['shuff3', '>30']=predict(df_,30)\n",
    "result_df.loc['shuff3', '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff4\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_45.reps.plk\")\n",
    "index = \"shuff4\"\n",
    "result_df.loc[index, 'no_con']=predict(df_,0)\n",
    "result_df.loc[index, '>200']= predict(df_,200)\n",
    "result_df.loc[index, '>100']=predict(df_,100)\n",
    "result_df.loc[index, '>70']=predict(df_,70)\n",
    "result_df.loc[index, '>50']=predict(df_,50)\n",
    "result_df.loc[index, '>30']=predict(df_,30)\n",
    "result_df.loc[index, '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff5\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_46.reps.plk\")\n",
    "index = \"shuff5\"\n",
    "result_df.loc[index, 'no_con']=predict(df_,0)\n",
    "result_df.loc[index, '>200']= predict(df_,200)\n",
    "result_df.loc[index, '>100']=predict(df_,100)\n",
    "result_df.loc[index, '>70']=predict(df_,70)\n",
    "result_df.loc[index, '>50']=predict(df_,50)\n",
    "result_df.loc[index, '>30']=predict(df_,30)\n",
    "result_df.loc[index, '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff6\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_47.reps.plk\")\n",
    "index = \"shuff6\"\n",
    "result_df.loc[index, 'no_con']=predict(df_,0)\n",
    "result_df.loc[index, '>200']= predict(df_,200)\n",
    "result_df.loc[index, '>100']=predict(df_,100)\n",
    "result_df.loc[index, '>70']=predict(df_,70)\n",
    "result_df.loc[index, '>50']=predict(df_,50)\n",
    "result_df.loc[index, '>30']=predict(df_,30)\n",
    "result_df.loc[index, '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff7\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_48.reps.plk\")\n",
    "index = \"shuff7\"\n",
    "result_df.loc[index, 'no_con']=predict(df_,0)\n",
    "result_df.loc[index, '>200']= predict(df_,200)\n",
    "result_df.loc[index, '>100']=predict(df_,100)\n",
    "result_df.loc[index, '>70']=predict(df_,70)\n",
    "result_df.loc[index, '>50']=predict(df_,50)\n",
    "result_df.loc[index, '>30']=predict(df_,30)\n",
    "result_df.loc[index, '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff8\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_49.reps.plk\")\n",
    "index = \"shuff8\"\n",
    "result_df.loc[index, 'no_con']=predict(df_,0)\n",
    "result_df.loc[index, '>200']= predict(df_,200)\n",
    "result_df.loc[index, '>100']=predict(df_,100)\n",
    "result_df.loc[index, '>70']=predict(df_,70)\n",
    "result_df.loc[index, '>50']=predict(df_,50)\n",
    "result_df.loc[index, '>30']=predict(df_,30)\n",
    "result_df.loc[index, '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff9\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_50.reps.plk\")\n",
    "index = \"shuff9\"\n",
    "result_df.loc[index, 'no_con']=predict(df_,0)\n",
    "result_df.loc[index, '>200']= predict(df_,200)\n",
    "result_df.loc[index, '>100']=predict(df_,100)\n",
    "result_df.loc[index, '>70']=predict(df_,70)\n",
    "result_df.loc[index, '>50']=predict(df_,50)\n",
    "result_df.loc[index, '>30']=predict(df_,30)\n",
    "result_df.loc[index, '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuff10\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_51.reps.plk\")\n",
    "index = \"shuff10\"\n",
    "result_df.loc[index, 'no_con']=predict(df_,0)\n",
    "result_df.loc[index, '>200']= predict(df_,200)\n",
    "result_df.loc[index, '>100']=predict(df_,100)\n",
    "result_df.loc[index, '>70']=predict(df_,70)\n",
    "result_df.loc[index, '>50']=predict(df_,50)\n",
    "result_df.loc[index, '>30']=predict(df_,30)\n",
    "result_df.loc[index, '30<=']=predict(df_,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_con</th>\n",
       "      <th>&gt;200</th>\n",
       "      <th>&gt;100</th>\n",
       "      <th>&gt;70</th>\n",
       "      <th>&gt;50</th>\n",
       "      <th>&gt;30</th>\n",
       "      <th>30&lt;=</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shuff1</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff2</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff3</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff4</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff5</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff6</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff7</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff8</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff9</th>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff10</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        no_con >200 >100 >70 >50 >30 30<=\n",
       "shuff1      25    3    4  11  14  20    5\n",
       "shuff2      34    2    2   9  20  26    8\n",
       "shuff3      26    4    4  10  13  18    8\n",
       "shuff4      22    4    6  10  12  16    6\n",
       "shuff5      27    4    6  11  13  19    8\n",
       "shuff6      33    3    4   8  16  24    9\n",
       "shuff7      25    3    5  10  15  19    6\n",
       "shuff8      26    2    3  10  13  18    8\n",
       "shuff9      37    4    5  10  23  28    9\n",
       "shuff10     24    3    5   9  10  18    6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN input 1900 + train on  short 30 AAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1900, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1900, 1900)        7600      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 950, 1900)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1805000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               231040128 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 231,049,029\n",
      "Trainable params: 231,049,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1900, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1900, 1900)        7600      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 950, 1900)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1805000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               231040128 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 231,049,029\n",
      "Trainable params: 231,049,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deployed_path = \"/mnt/vdb/thesis/best_CNN.1900._30.testagin.hdf5\" #\"/mnt/vdb/thesis/best_CNN.1900._30.hdf5\" \n",
    "#deployed_path = \"TubularLearner.fastAI._stage2.pth\"\n",
    "learner = load_model(deployed_path)\n",
    "def predict_DNN(_df ,condition):\n",
    "    #df = _df.loc[_df.length > 30 ].copy() \n",
    "    #df = _df.loc[_df.length <= 30 ].copy()\n",
    "    if condition == 0:\n",
    "        df = _df.copy()\n",
    "    elif condition == -1 :\n",
    "        df = _df.loc[_df.length <= 30 ].copy()\n",
    "    else:\n",
    "        df = _df.loc[_df.length > condition ].copy() # select records with lenght > \n",
    "    #print(df.columns)\n",
    "    X= np.array(df['reps'].to_list())\n",
    "    X_test = np.reshape(X,(X.shape[0],X.shape[1],1))\n",
    "    y_probas = learner.predict(X_test)\n",
    "    threshold = 0.5\n",
    "    _y = np.where(y_probas > threshold, 1, 0)\n",
    "    \n",
    "    df['class'] = _y\n",
    "    #df.drop(columns=['reps'],inplace =True)\n",
    "    accuracy = (len(df[df[\"class\"] == 1])/len(df) )*100\n",
    "    #print(\"predict AMP :\"+str(len(df[df[\"class\"] == 0])))\n",
    "    #print(\"predict NonAMP:\"+str(len(df[df[\"class\"] == 1])))\n",
    "    #print(\"predict NonAMP (in percentage):\"+str(accuracy))\n",
    "    return len(df[df[\"class\"] == 1])\n",
    "\n",
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_con</th>\n",
       "      <th>&gt;200</th>\n",
       "      <th>&gt;100</th>\n",
       "      <th>&gt;70</th>\n",
       "      <th>&gt;50</th>\n",
       "      <th>&gt;30</th>\n",
       "      <th>30&lt;=</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shuff1</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff2</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff3</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff4</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff5</th>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff6</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff7</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff8</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff9</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff10</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        no_con >200 >100 >70 >50 >30 30<=\n",
       "shuff1      15    4    7  10  10  12    3\n",
       "shuff2      23    4    7  16  18  22    1\n",
       "shuff3      22    4    7  10  13  18    4\n",
       "shuff4      17    4    7   8   8  11    6\n",
       "shuff5      19    4    6   8   8  13    6\n",
       "shuff6      28    4    7  13  18  24    4\n",
       "shuff7      31    4    7   9  18  24    7\n",
       "shuff8      21    4    7   9  10  16    5\n",
       "shuff9      17    4    6   9  13  14    3\n",
       "shuff10     20    4    7  11  12  15    5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame( columns=[\"no_con\",\">200\",\">100\",\">70\",\">50\",\">30\",\"30<=\"],\n",
    "    index = ['shuff1','shuff2', 'shuff3',\"shuff4\",\"shuff5\",\"shuff6\",\"shuff7\",\"shuff8\",\"shuff9\",\"shuff10\"])\n",
    "# shuff1\n",
    "index = \"shuff1\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_42.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff2\n",
    "index = \"shuff2\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_43.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff3\n",
    "index = \"shuff3\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_44.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff4\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_45.reps.plk\")\n",
    "index = \"shuff4\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff5\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_46.reps.plk\")\n",
    "index = \"shuff5\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff6\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_47.reps.plk\")\n",
    "index = \"shuff6\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff7\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_48.reps.plk\")\n",
    "index = \"shuff7\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff8\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_49.reps.plk\")\n",
    "index = \"shuff8\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff9\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_50.reps.plk\")\n",
    "index = \"shuff9\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff10\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_51.reps.plk\")\n",
    "index = \"shuff10\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN from Deep-AmPEP30 short 30 AAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_path = \"/mnt/vdb/thesis/best_CNN._30.hdf5\"\n",
    "#deployed_path = \"TubularLearner.fastAI._stage2.pth\"\n",
    "learner = load_model(deployed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_con</th>\n",
       "      <th>&gt;200</th>\n",
       "      <th>&gt;100</th>\n",
       "      <th>&gt;70</th>\n",
       "      <th>&gt;50</th>\n",
       "      <th>&gt;30</th>\n",
       "      <th>30&lt;=</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>shuff1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff2</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff4</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff5</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff6</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff7</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff9</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shuff10</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        no_con >200 >100 >70 >50 >30 30<=\n",
       "shuff1      15    0    3   5   8  12    3\n",
       "shuff2      26    0    3  12  19  23    3\n",
       "shuff3      23    0    3  11  14  20    3\n",
       "shuff4      10    0    3   4   4   6    4\n",
       "shuff5      13    1    2   5   5  12    1\n",
       "shuff6      23    1    4  11  16  18    5\n",
       "shuff7      27    0    3   5  16  21    6\n",
       "shuff8       9    0    3   4   5   6    3\n",
       "shuff9      23    0    3   8  21  22    1\n",
       "shuff10     17    0    3   7   8  10    7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame( columns=[\"no_con\",\">200\",\">100\",\">70\",\">50\",\">30\",\"30<=\"],\n",
    "    index = ['shuff1','shuff2', 'shuff3',\"shuff4\",\"shuff5\",\"shuff6\",\"shuff7\",\"shuff8\",\"shuff9\",\"shuff10\"])\n",
    "# shuff1\n",
    "index = \"shuff1\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_42.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff2\n",
    "index = \"shuff2\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_43.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff3\n",
    "index = \"shuff3\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_44.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff4\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_45.reps.plk\")\n",
    "index = \"shuff4\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff5\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_46.reps.plk\")\n",
    "index = \"shuff5\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff6\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_47.reps.plk\")\n",
    "index = \"shuff6\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff7\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_48.reps.plk\")\n",
    "index = \"shuff7\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff8\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_49.reps.plk\")\n",
    "index = \"shuff8\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff9\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_50.reps.plk\")\n",
    "index = \"shuff9\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff10\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_51.reps.plk\")\n",
    "index = \"shuff10\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: Functional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-eda3031dd56b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdeployed_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/mnt/vdb/thesis/AmPPEP30.1900.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#deployed_path = \"TubularLearner.fastAI._stage2.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeployed_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m result_df = pd.DataFrame( columns=[\"no_con\",\">200\",\">100\",\">70\",\">50\",\">30\",\"30<=\"],\n\u001b[1;32m      6\u001b[0m     index = ['shuff1','shuff2', 'shuff3',\"shuff4\",\"shuff5\",\"shuff6\",\"shuff7\",\"shuff8\",\"shuff9\",\"shuff10\"])\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    625\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 140\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: Functional"
     ]
    }
   ],
   "source": [
    "## Retrain 256\n",
    "deployed_path = \"/mnt/vdb/thesis/AmPPEP30.1900.hdf5\"\n",
    "#deployed_path = \"TubularLearner.fastAI._stage2.pth\"\n",
    "learner = load_model(deployed_path)\n",
    "result_df = pd.DataFrame( columns=[\"no_con\",\">200\",\">100\",\">70\",\">50\",\">30\",\"30<=\"],\n",
    "    index = ['shuff1','shuff2', 'shuff3',\"shuff4\",\"shuff5\",\"shuff6\",\"shuff7\",\"shuff8\",\"shuff9\",\"shuff10\"])\n",
    "# shuff1\n",
    "index = \"shuff1\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_42.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff2\n",
    "index = \"shuff2\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_43.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff3\n",
    "index = \"shuff3\"\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_44.reps.plk\")\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff4\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_45.reps.plk\")\n",
    "index = \"shuff4\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff5\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_46.reps.plk\")\n",
    "index = \"shuff5\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff6\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_47.reps.plk\")\n",
    "index = \"shuff6\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff7\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_48.reps.plk\")\n",
    "index = \"shuff7\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff8\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_49.reps.plk\")\n",
    "index = \"shuff8\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff9\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_50.reps.plk\")\n",
    "index = \"shuff9\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "# shuff10\n",
    "df_ = pd.read_pickle(\"../datasets/truthset/AMPs_truthset_51.reps.plk\")\n",
    "index = \"shuff10\"\n",
    "result_df.loc[index, 'no_con']=predict_DNN(df_,0)\n",
    "result_df.loc[index, '>200']= predict_DNN(df_,200)\n",
    "result_df.loc[index, '>100']=predict_DNN(df_,100)\n",
    "result_df.loc[index, '>70']=predict_DNN(df_,70)\n",
    "result_df.loc[index, '>50']=predict_DNN(df_,50)\n",
    "result_df.loc[index, '>30']=predict_DNN(df_,30)\n",
    "result_df.loc[index, '30<=']=predict_DNN(df_,-1)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "FASTAI_predictor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
