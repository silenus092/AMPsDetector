{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import pickle5 as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open( \"/mnt/vdb/thesis/jax/AMPNonAMP.V5_C08_sim60.reps\", 'rb') as file:\n",
    "    AMPs_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMPs_df.drop_duplicates(subset=['Sequence'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1891</th>\n",
       "      <th>1892</th>\n",
       "      <th>1893</th>\n",
       "      <th>1894</th>\n",
       "      <th>1895</th>\n",
       "      <th>1896</th>\n",
       "      <th>1897</th>\n",
       "      <th>1898</th>\n",
       "      <th>1899</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.020596</td>\n",
       "      <td>0.051454</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>-0.158560</td>\n",
       "      <td>0.096443</td>\n",
       "      <td>-0.280527</td>\n",
       "      <td>-0.004144</td>\n",
       "      <td>-0.024222</td>\n",
       "      <td>0.139821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>-0.178922</td>\n",
       "      <td>0.061034</td>\n",
       "      <td>-0.049153</td>\n",
       "      <td>-0.008552</td>\n",
       "      <td>0.295699</td>\n",
       "      <td>0.078237</td>\n",
       "      <td>0.084181</td>\n",
       "      <td>-0.002584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.006680</td>\n",
       "      <td>-0.095586</td>\n",
       "      <td>0.059442</td>\n",
       "      <td>-0.021558</td>\n",
       "      <td>0.138408</td>\n",
       "      <td>-0.023227</td>\n",
       "      <td>-0.168920</td>\n",
       "      <td>-0.101124</td>\n",
       "      <td>-0.007432</td>\n",
       "      <td>0.117733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028154</td>\n",
       "      <td>-0.020222</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.140324</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>-0.013351</td>\n",
       "      <td>-0.060497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>-0.010357</td>\n",
       "      <td>-0.001492</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>-0.232180</td>\n",
       "      <td>-0.016746</td>\n",
       "      <td>-0.010970</td>\n",
       "      <td>0.026109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133411</td>\n",
       "      <td>-0.094850</td>\n",
       "      <td>0.031804</td>\n",
       "      <td>-0.086968</td>\n",
       "      <td>-0.029461</td>\n",
       "      <td>0.069626</td>\n",
       "      <td>0.047517</td>\n",
       "      <td>0.130172</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.002073</td>\n",
       "      <td>-0.076902</td>\n",
       "      <td>-0.021565</td>\n",
       "      <td>0.016011</td>\n",
       "      <td>-0.059204</td>\n",
       "      <td>0.027183</td>\n",
       "      <td>-0.491927</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>-0.020296</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>-0.125865</td>\n",
       "      <td>0.025240</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.028679</td>\n",
       "      <td>0.384807</td>\n",
       "      <td>0.030021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.029898</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>-0.015070</td>\n",
       "      <td>0.031181</td>\n",
       "      <td>-0.066619</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>-0.388183</td>\n",
       "      <td>-0.017860</td>\n",
       "      <td>-0.035654</td>\n",
       "      <td>0.172902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017706</td>\n",
       "      <td>-0.102827</td>\n",
       "      <td>0.035134</td>\n",
       "      <td>0.017357</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.447118</td>\n",
       "      <td>0.093590</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.013467</td>\n",
       "      <td>-0.135259</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>-0.242629</td>\n",
       "      <td>-0.004931</td>\n",
       "      <td>-0.015722</td>\n",
       "      <td>0.167582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067011</td>\n",
       "      <td>-0.050945</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.042930</td>\n",
       "      <td>0.086973</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.206966</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.019307</td>\n",
       "      <td>-0.030070</td>\n",
       "      <td>-0.012818</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.020863</td>\n",
       "      <td>0.016052</td>\n",
       "      <td>-0.325731</td>\n",
       "      <td>-0.042692</td>\n",
       "      <td>-0.017072</td>\n",
       "      <td>0.111204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>-0.156615</td>\n",
       "      <td>0.030351</td>\n",
       "      <td>-0.023633</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.026462</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>0.140177</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008608</td>\n",
       "      <td>-0.057360</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>-0.079074</td>\n",
       "      <td>0.019588</td>\n",
       "      <td>-0.113827</td>\n",
       "      <td>-0.013885</td>\n",
       "      <td>-0.014072</td>\n",
       "      <td>0.050159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>-0.124026</td>\n",
       "      <td>0.029327</td>\n",
       "      <td>-0.062297</td>\n",
       "      <td>-0.022352</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.120658</td>\n",
       "      <td>0.082524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.014597</td>\n",
       "      <td>-0.139941</td>\n",
       "      <td>0.026719</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>-0.017684</td>\n",
       "      <td>0.038440</td>\n",
       "      <td>-0.253193</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>-0.015894</td>\n",
       "      <td>0.151149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062336</td>\n",
       "      <td>-0.044791</td>\n",
       "      <td>-0.008192</td>\n",
       "      <td>0.044289</td>\n",
       "      <td>0.043903</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>-0.006654</td>\n",
       "      <td>0.192273</td>\n",
       "      <td>0.040663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.007431</td>\n",
       "      <td>-0.062929</td>\n",
       "      <td>0.021139</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>-0.084893</td>\n",
       "      <td>0.009822</td>\n",
       "      <td>-0.074385</td>\n",
       "      <td>-0.011151</td>\n",
       "      <td>-0.014763</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002755</td>\n",
       "      <td>-0.119420</td>\n",
       "      <td>0.034385</td>\n",
       "      <td>-0.046803</td>\n",
       "      <td>-0.026525</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>0.082130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137389 rows × 1901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "210  0.020596  0.051454  0.009273  0.008583 -0.158560  0.096443 -0.280527   \n",
       "371  0.006680 -0.095586  0.059442 -0.021558  0.138408 -0.023227 -0.168920   \n",
       "420  0.010706  0.005045  0.022312 -0.010357 -0.001492  0.035573 -0.232180   \n",
       "168  0.002073 -0.076902 -0.021565  0.016011 -0.059204  0.027183 -0.491927   \n",
       "344  0.029898 -0.004466 -0.015070  0.031181 -0.066619  0.152418 -0.388183   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "471  0.013467 -0.135259  0.022123  0.004654  0.001060  0.035953 -0.242629   \n",
       "447  0.019307 -0.030070 -0.012818  0.012989  0.020863  0.016052 -0.325731   \n",
       "5    0.008608 -0.057360  0.019528  0.004598 -0.079074  0.019588 -0.113827   \n",
       "477  0.014597 -0.139941  0.026719  0.003316 -0.017684  0.038440 -0.253193   \n",
       "341  0.007431 -0.062929  0.021139  0.005992 -0.084893  0.009822 -0.074385   \n",
       "\n",
       "            7         8         9  ...      1891      1892      1893  \\\n",
       "210 -0.004144 -0.024222  0.139821  ...  0.017658 -0.178922  0.061034   \n",
       "371 -0.101124 -0.007432  0.117733  ...  0.028154 -0.020222  0.024706   \n",
       "420 -0.016746 -0.010970  0.026109  ...  0.133411 -0.094850  0.031804   \n",
       "168  0.013376 -0.020296  0.069320  ...  0.020355 -0.125865  0.025240   \n",
       "344 -0.017860 -0.035654  0.172902  ... -0.017706 -0.102827  0.035134   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "471 -0.004931 -0.015722  0.167582  ...  0.067011 -0.050945  0.003909   \n",
       "447 -0.042692 -0.017072  0.111204  ...  0.015929 -0.156615  0.030351   \n",
       "5   -0.013885 -0.014072  0.050159  ...  0.008678 -0.124026  0.029327   \n",
       "477 -0.000880 -0.015894  0.151149  ...  0.062336 -0.044791 -0.008192   \n",
       "341 -0.011151 -0.014763  0.014829  ... -0.002755 -0.119420  0.034385   \n",
       "\n",
       "         1894      1895      1896      1897      1898      1899  class  \n",
       "210 -0.049153 -0.008552  0.295699  0.078237  0.084181 -0.002584      0  \n",
       "371 -0.072173  0.014760  0.140324  0.024822 -0.013351 -0.060497      0  \n",
       "420 -0.086968 -0.029461  0.069626  0.047517  0.130172  0.006449      0  \n",
       "168  0.004637 -0.003113  0.012125  0.028679  0.384807  0.030021      0  \n",
       "344  0.017357  0.010981  0.447118  0.093590  0.055483  0.014400      0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "471  0.007646  0.042930  0.086973  0.000517  0.206966  0.017166      0  \n",
       "447 -0.023633  0.000660  0.026462 -0.004548  0.140177  0.027681      0  \n",
       "5   -0.062297 -0.022352  0.069006  0.003294  0.120658  0.082524      0  \n",
       "477  0.044289  0.043903  0.078633 -0.006654  0.192273  0.040663      0  \n",
       "341 -0.046803 -0.026525  0.077348  0.007957  0.099998  0.082130      0  \n",
       "\n",
       "[137389 rows x 1901 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df =AMPs_df[[\"reps\",\"class\"]]\n",
    "df\n",
    "df_new = df.reps.apply(pd.Series).astype(np.float64)\n",
    "df_new['class'] = df['class']\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.iloc[:,:-1]\n",
    "y = df_new.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1890</th>\n",
       "      <th>1891</th>\n",
       "      <th>1892</th>\n",
       "      <th>1893</th>\n",
       "      <th>1894</th>\n",
       "      <th>1895</th>\n",
       "      <th>1896</th>\n",
       "      <th>1897</th>\n",
       "      <th>1898</th>\n",
       "      <th>1899</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.020596</td>\n",
       "      <td>0.051454</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>-0.158560</td>\n",
       "      <td>0.096443</td>\n",
       "      <td>-0.280527</td>\n",
       "      <td>-0.004144</td>\n",
       "      <td>-0.024222</td>\n",
       "      <td>0.139821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064921</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>-0.178922</td>\n",
       "      <td>0.061034</td>\n",
       "      <td>-0.049153</td>\n",
       "      <td>-0.008552</td>\n",
       "      <td>0.295699</td>\n",
       "      <td>0.078237</td>\n",
       "      <td>0.084181</td>\n",
       "      <td>-0.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.006680</td>\n",
       "      <td>-0.095586</td>\n",
       "      <td>0.059442</td>\n",
       "      <td>-0.021558</td>\n",
       "      <td>0.138408</td>\n",
       "      <td>-0.023227</td>\n",
       "      <td>-0.168920</td>\n",
       "      <td>-0.101124</td>\n",
       "      <td>-0.007432</td>\n",
       "      <td>0.117733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092843</td>\n",
       "      <td>0.028154</td>\n",
       "      <td>-0.020222</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.140324</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>-0.013351</td>\n",
       "      <td>-0.060497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>-0.010357</td>\n",
       "      <td>-0.001492</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>-0.232180</td>\n",
       "      <td>-0.016746</td>\n",
       "      <td>-0.010970</td>\n",
       "      <td>0.026109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048697</td>\n",
       "      <td>0.133411</td>\n",
       "      <td>-0.094850</td>\n",
       "      <td>0.031804</td>\n",
       "      <td>-0.086968</td>\n",
       "      <td>-0.029461</td>\n",
       "      <td>0.069626</td>\n",
       "      <td>0.047517</td>\n",
       "      <td>0.130172</td>\n",
       "      <td>0.006449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.002073</td>\n",
       "      <td>-0.076902</td>\n",
       "      <td>-0.021565</td>\n",
       "      <td>0.016011</td>\n",
       "      <td>-0.059204</td>\n",
       "      <td>0.027183</td>\n",
       "      <td>-0.491927</td>\n",
       "      <td>0.013376</td>\n",
       "      <td>-0.020296</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037901</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>-0.125865</td>\n",
       "      <td>0.025240</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>0.012125</td>\n",
       "      <td>0.028679</td>\n",
       "      <td>0.384807</td>\n",
       "      <td>0.030021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.029898</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>-0.015070</td>\n",
       "      <td>0.031181</td>\n",
       "      <td>-0.066619</td>\n",
       "      <td>0.152418</td>\n",
       "      <td>-0.388183</td>\n",
       "      <td>-0.017860</td>\n",
       "      <td>-0.035654</td>\n",
       "      <td>0.172902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037580</td>\n",
       "      <td>-0.017706</td>\n",
       "      <td>-0.102827</td>\n",
       "      <td>0.035134</td>\n",
       "      <td>0.017357</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.447118</td>\n",
       "      <td>0.093590</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.013467</td>\n",
       "      <td>-0.135259</td>\n",
       "      <td>0.022123</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>-0.242629</td>\n",
       "      <td>-0.004931</td>\n",
       "      <td>-0.015722</td>\n",
       "      <td>0.167582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022613</td>\n",
       "      <td>0.067011</td>\n",
       "      <td>-0.050945</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.042930</td>\n",
       "      <td>0.086973</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.206966</td>\n",
       "      <td>0.017166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.019307</td>\n",
       "      <td>-0.030070</td>\n",
       "      <td>-0.012818</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.020863</td>\n",
       "      <td>0.016052</td>\n",
       "      <td>-0.325731</td>\n",
       "      <td>-0.042692</td>\n",
       "      <td>-0.017072</td>\n",
       "      <td>0.111204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049278</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>-0.156615</td>\n",
       "      <td>0.030351</td>\n",
       "      <td>-0.023633</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.026462</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>0.140177</td>\n",
       "      <td>0.027681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008608</td>\n",
       "      <td>-0.057360</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>-0.079074</td>\n",
       "      <td>0.019588</td>\n",
       "      <td>-0.113827</td>\n",
       "      <td>-0.013885</td>\n",
       "      <td>-0.014072</td>\n",
       "      <td>0.050159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069397</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>-0.124026</td>\n",
       "      <td>0.029327</td>\n",
       "      <td>-0.062297</td>\n",
       "      <td>-0.022352</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.120658</td>\n",
       "      <td>0.082524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.014597</td>\n",
       "      <td>-0.139941</td>\n",
       "      <td>0.026719</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>-0.017684</td>\n",
       "      <td>0.038440</td>\n",
       "      <td>-0.253193</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>-0.015894</td>\n",
       "      <td>0.151149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023765</td>\n",
       "      <td>0.062336</td>\n",
       "      <td>-0.044791</td>\n",
       "      <td>-0.008192</td>\n",
       "      <td>0.044289</td>\n",
       "      <td>0.043903</td>\n",
       "      <td>0.078633</td>\n",
       "      <td>-0.006654</td>\n",
       "      <td>0.192273</td>\n",
       "      <td>0.040663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.007431</td>\n",
       "      <td>-0.062929</td>\n",
       "      <td>0.021139</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>-0.084893</td>\n",
       "      <td>0.009822</td>\n",
       "      <td>-0.074385</td>\n",
       "      <td>-0.011151</td>\n",
       "      <td>-0.014763</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>-0.002755</td>\n",
       "      <td>-0.119420</td>\n",
       "      <td>0.034385</td>\n",
       "      <td>-0.046803</td>\n",
       "      <td>-0.026525</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>0.099998</td>\n",
       "      <td>0.082130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137389 rows × 1900 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "210  0.020596  0.051454  0.009273  0.008583 -0.158560  0.096443 -0.280527   \n",
       "371  0.006680 -0.095586  0.059442 -0.021558  0.138408 -0.023227 -0.168920   \n",
       "420  0.010706  0.005045  0.022312 -0.010357 -0.001492  0.035573 -0.232180   \n",
       "168  0.002073 -0.076902 -0.021565  0.016011 -0.059204  0.027183 -0.491927   \n",
       "344  0.029898 -0.004466 -0.015070  0.031181 -0.066619  0.152418 -0.388183   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "471  0.013467 -0.135259  0.022123  0.004654  0.001060  0.035953 -0.242629   \n",
       "447  0.019307 -0.030070 -0.012818  0.012989  0.020863  0.016052 -0.325731   \n",
       "5    0.008608 -0.057360  0.019528  0.004598 -0.079074  0.019588 -0.113827   \n",
       "477  0.014597 -0.139941  0.026719  0.003316 -0.017684  0.038440 -0.253193   \n",
       "341  0.007431 -0.062929  0.021139  0.005992 -0.084893  0.009822 -0.074385   \n",
       "\n",
       "         7         8         9     ...      1890      1891      1892  \\\n",
       "210 -0.004144 -0.024222  0.139821  ...  0.064921  0.017658 -0.178922   \n",
       "371 -0.101124 -0.007432  0.117733  ...  0.092843  0.028154 -0.020222   \n",
       "420 -0.016746 -0.010970  0.026109  ...  0.048697  0.133411 -0.094850   \n",
       "168  0.013376 -0.020296  0.069320  ...  0.037901  0.020355 -0.125865   \n",
       "344 -0.017860 -0.035654  0.172902  ...  0.037580 -0.017706 -0.102827   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "471 -0.004931 -0.015722  0.167582  ...  0.022613  0.067011 -0.050945   \n",
       "447 -0.042692 -0.017072  0.111204  ...  0.049278  0.015929 -0.156615   \n",
       "5   -0.013885 -0.014072  0.050159  ...  0.069397  0.008678 -0.124026   \n",
       "477 -0.000880 -0.015894  0.151149  ...  0.023765  0.062336 -0.044791   \n",
       "341 -0.011151 -0.014763  0.014829  ...  0.062600 -0.002755 -0.119420   \n",
       "\n",
       "         1893      1894      1895      1896      1897      1898      1899  \n",
       "210  0.061034 -0.049153 -0.008552  0.295699  0.078237  0.084181 -0.002584  \n",
       "371  0.024706 -0.072173  0.014760  0.140324  0.024822 -0.013351 -0.060497  \n",
       "420  0.031804 -0.086968 -0.029461  0.069626  0.047517  0.130172  0.006449  \n",
       "168  0.025240  0.004637 -0.003113  0.012125  0.028679  0.384807  0.030021  \n",
       "344  0.035134  0.017357  0.010981  0.447118  0.093590  0.055483  0.014400  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "471  0.003909  0.007646  0.042930  0.086973  0.000517  0.206966  0.017166  \n",
       "447  0.030351 -0.023633  0.000660  0.026462 -0.004548  0.140177  0.027681  \n",
       "5    0.029327 -0.062297 -0.022352  0.069006  0.003294  0.120658  0.082524  \n",
       "477 -0.008192  0.044289  0.043903  0.078633 -0.006654  0.192273  0.040663  \n",
       "341  0.034385 -0.046803 -0.026525  0.077348  0.007957  0.099998  0.082130  \n",
       "\n",
       "[137389 rows x 1900 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RFclassifier = RandomForestClassifier ( random_state=42)\n",
    "RFclassifier.fit(X_train, y_train)\n",
    "y_pred = RFclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      4335\n",
      "           1       0.90      0.91      0.91      4056\n",
      "\n",
      "    accuracy                           0.91      8391\n",
      "   macro avg       0.91      0.91      0.91      8391\n",
      "weighted avg       0.91      0.91      0.91      8391\n",
      "\n",
      "0.9094267667739244\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_Matrix(classifier, X_test, y_test):\n",
    "    class_names = ['AMPs', 'NonAMPs']\n",
    "\n",
    "    disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "                                display_labels = class_names,\n",
    "                                cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "\n",
    "    disp.ax_.set_title(\" Confusion Matrix\")\n",
    "\n",
    "    print(disp.confusion_matrix)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X= np.array(AMPs_df['reps'].to_list())\n",
    "#y= np.array(AMPs_df['class'].to_list())\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(AMPs_df['reps'].to_list()), np.array(AMPs_df['class'].to_list()), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFclassifier = RandomForestClassifier ( random_state=42)\n",
    "RFclassifier.fit(X_train, y_train)\n",
    "y_pred = RFclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     13914\n",
      "           1       0.91      0.92      0.92     13564\n",
      "\n",
      "    accuracy                           0.92     27478\n",
      "   macro avg       0.92      0.92      0.92     27478\n",
      "weighted avg       0.92      0.92      0.92     27478\n",
      "\n",
      "0.9160055316980857\n",
      "[[12659  1255]\n",
      " [ 1053 12511]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "confusion_Matrix(RFclassifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/vdb/thesis/best_RF.model', 'wb') as f:\n",
    "    pickle.dump(RFclassifier, f)\n",
    "#RFclassifier.save_model( \"best_RF.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "scoring = ['accuracy', 'f1', 'roc_auc', 'recall', 'precision','neg_log_loss']\n",
    "scores = cross_validate(\n",
    "    RFclassifier, X_test, y_test, scoring=scoring, cv=kfold, return_train_score=True)\n",
    "print(\"Accuracy TEST: %0.2f (+/- %0.2f) Accuracy TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2, scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
    "print(\"F1 TEST: %0.2f (+/- %0.2f) F1 TRAIN : %0.2f (+/- %0.2f) \" %\n",
    "      (scores['test_f1'].mean(), scores['test_f1'].std() * 2, scores['train_f1'].mean(), scores['train_f1'].std() * 2))\n",
    "print(\"AUROC TEST: %0.2f (+/- %0.2f) AUROC TRAIN : %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_roc_auc'].mean(), scores['test_roc_auc'].std() * 2, scores['train_roc_auc'].mean(), scores['train_roc_auc'].std() * 2))\n",
    "print(\"recall TEST: %0.2f (+/- %0.2f) recall TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_recall'].mean(), scores['test_recall'].std() * 2, scores['train_recall'].mean(), scores['train_recall'].std() * 2))\n",
    "print(\"Precision TEST: %0.2f (+/- %0.2f) Precision TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_precision'].mean(), scores['test_precision'].std() * 2, scores['train_precision'].mean(), scores['train_precision'].std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PWS RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( '/mnt/vdb/thesis/pwm/AMPnonAMP.sim60_c08.pssm.pkl', 'rb') as file:\n",
    "    AMPNonAMP_df = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Y1 =np.array([0] * 68869 + [1] * 68520)\n",
    "##X_train, X_test, y_train, y_test = train_test_split(AMPNonAMP_df, Y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(AMPNonAMP_df['reps'].to_list())\n",
    "y= np.array(AMPNonAMP_df['class'].to_list())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      8726\n",
      "           1       0.84      0.89      0.86      8566\n",
      "\n",
      "    accuracy                           0.86     17292\n",
      "   macro avg       0.86      0.86      0.86     17292\n",
      "weighted avg       0.86      0.86      0.86     17292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RFclassifier = RandomForestClassifier ( random_state=42)\n",
    "RFclassifier.fit(X_train, y_train)\n",
    "y_pred = RFclassifier.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/vdb/thesis/best_RF.model', 'wb') as f:\n",
    "    pickle.dump(RFclassifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
