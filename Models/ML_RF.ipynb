{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "with open( \"/mnt/vdb/thesis/jax/AMPNonAMP.final.reps\", 'rb') as file:\n",
    "    AMPs_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1891</th>\n",
       "      <th>1892</th>\n",
       "      <th>1893</th>\n",
       "      <th>1894</th>\n",
       "      <th>1895</th>\n",
       "      <th>1896</th>\n",
       "      <th>1897</th>\n",
       "      <th>1898</th>\n",
       "      <th>1899</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.073286</td>\n",
       "      <td>0.039610</td>\n",
       "      <td>-0.081396</td>\n",
       "      <td>-0.097664</td>\n",
       "      <td>-0.009299</td>\n",
       "      <td>0.141095</td>\n",
       "      <td>-0.014705</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.017338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038974</td>\n",
       "      <td>-0.041898</td>\n",
       "      <td>0.014611</td>\n",
       "      <td>-0.140464</td>\n",
       "      <td>-0.159461</td>\n",
       "      <td>0.172770</td>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.130533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.069160</td>\n",
       "      <td>0.034436</td>\n",
       "      <td>-0.074240</td>\n",
       "      <td>-0.091777</td>\n",
       "      <td>-0.012302</td>\n",
       "      <td>0.129554</td>\n",
       "      <td>-0.013877</td>\n",
       "      <td>-0.002370</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>-0.053930</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>-0.146390</td>\n",
       "      <td>-0.160165</td>\n",
       "      <td>0.184182</td>\n",
       "      <td>0.034579</td>\n",
       "      <td>-0.002108</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.029643</td>\n",
       "      <td>-0.077715</td>\n",
       "      <td>-0.102382</td>\n",
       "      <td>-0.018419</td>\n",
       "      <td>0.130293</td>\n",
       "      <td>-0.010733</td>\n",
       "      <td>-0.001927</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032786</td>\n",
       "      <td>-0.045271</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>-0.131867</td>\n",
       "      <td>-0.132735</td>\n",
       "      <td>0.214412</td>\n",
       "      <td>0.028494</td>\n",
       "      <td>-0.030600</td>\n",
       "      <td>0.124883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.071879</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>-0.062474</td>\n",
       "      <td>-0.208573</td>\n",
       "      <td>-0.070853</td>\n",
       "      <td>0.098093</td>\n",
       "      <td>-0.029980</td>\n",
       "      <td>-0.001456</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>-0.011020</td>\n",
       "      <td>-0.015470</td>\n",
       "      <td>-0.157489</td>\n",
       "      <td>-0.096212</td>\n",
       "      <td>0.107507</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.144605</td>\n",
       "      <td>0.038405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>0.042706</td>\n",
       "      <td>-0.037508</td>\n",
       "      <td>-0.253113</td>\n",
       "      <td>-0.006857</td>\n",
       "      <td>-0.145191</td>\n",
       "      <td>-0.010647</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>0.064441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042877</td>\n",
       "      <td>-0.034219</td>\n",
       "      <td>0.020791</td>\n",
       "      <td>-0.033644</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.299079</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42439</th>\n",
       "      <td>0.047398</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>-0.039842</td>\n",
       "      <td>0.050582</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.068586</td>\n",
       "      <td>-0.219056</td>\n",
       "      <td>-0.202724</td>\n",
       "      <td>-0.055616</td>\n",
       "      <td>0.250190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069892</td>\n",
       "      <td>-0.027141</td>\n",
       "      <td>0.051759</td>\n",
       "      <td>0.039957</td>\n",
       "      <td>0.024313</td>\n",
       "      <td>0.275040</td>\n",
       "      <td>0.092340</td>\n",
       "      <td>0.051801</td>\n",
       "      <td>0.044719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42440</th>\n",
       "      <td>0.048349</td>\n",
       "      <td>-0.007824</td>\n",
       "      <td>-0.033272</td>\n",
       "      <td>0.051004</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.054971</td>\n",
       "      <td>-0.509455</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>-0.056100</td>\n",
       "      <td>0.225375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104017</td>\n",
       "      <td>-0.082060</td>\n",
       "      <td>0.045554</td>\n",
       "      <td>0.038322</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.088050</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>0.074435</td>\n",
       "      <td>0.124462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42441</th>\n",
       "      <td>0.047338</td>\n",
       "      <td>-0.013988</td>\n",
       "      <td>-0.038846</td>\n",
       "      <td>0.051135</td>\n",
       "      <td>0.025912</td>\n",
       "      <td>0.071711</td>\n",
       "      <td>-0.449391</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>-0.055574</td>\n",
       "      <td>0.407604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156391</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>0.058176</td>\n",
       "      <td>0.037907</td>\n",
       "      <td>0.035981</td>\n",
       "      <td>0.115794</td>\n",
       "      <td>0.084910</td>\n",
       "      <td>0.052877</td>\n",
       "      <td>0.029546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42442</th>\n",
       "      <td>0.046977</td>\n",
       "      <td>-0.027571</td>\n",
       "      <td>-0.030715</td>\n",
       "      <td>0.050779</td>\n",
       "      <td>-0.116802</td>\n",
       "      <td>0.074466</td>\n",
       "      <td>-0.375273</td>\n",
       "      <td>0.040132</td>\n",
       "      <td>-0.056104</td>\n",
       "      <td>0.356369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086769</td>\n",
       "      <td>-0.134194</td>\n",
       "      <td>0.059559</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>0.087329</td>\n",
       "      <td>0.049971</td>\n",
       "      <td>0.085940</td>\n",
       "      <td>0.047609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42443</th>\n",
       "      <td>0.047497</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>-0.033763</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>-0.575566</td>\n",
       "      <td>0.042462</td>\n",
       "      <td>-0.055821</td>\n",
       "      <td>0.534847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342058</td>\n",
       "      <td>-0.100431</td>\n",
       "      <td>0.058591</td>\n",
       "      <td>0.045007</td>\n",
       "      <td>0.042174</td>\n",
       "      <td>0.047897</td>\n",
       "      <td>0.121984</td>\n",
       "      <td>0.111572</td>\n",
       "      <td>0.031473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41951 rows × 1901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.003220  0.073286  0.039610 -0.081396 -0.097664 -0.009299  0.141095   \n",
       "1      0.002793  0.069160  0.034436 -0.074240 -0.091777 -0.012302  0.129554   \n",
       "2      0.002317  0.054063  0.029643 -0.077715 -0.102382 -0.018419  0.130293   \n",
       "3      0.014645  0.071879  0.034763 -0.062474 -0.208573 -0.070853  0.098093   \n",
       "4      0.006236  0.018485  0.042706 -0.037508 -0.253113 -0.006857 -0.145191   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "42439  0.047398  0.019436 -0.039842  0.050582  0.031774  0.068586 -0.219056   \n",
       "42440  0.048349 -0.007824 -0.033272  0.051004  0.013359  0.054971 -0.509455   \n",
       "42441  0.047338 -0.013988 -0.038846  0.051135  0.025912  0.071711 -0.449391   \n",
       "42442  0.046977 -0.027571 -0.030715  0.050779 -0.116802  0.074466 -0.375273   \n",
       "42443  0.047497  0.005815 -0.033763  0.051256  0.012093  0.054598 -0.575566   \n",
       "\n",
       "              7         8         9  ...      1891      1892      1893  \\\n",
       "0     -0.014705 -0.002360  0.017338  ...  0.038974 -0.041898  0.014611   \n",
       "1     -0.013877 -0.002370  0.006206  ...  0.032007 -0.053930  0.010304   \n",
       "2     -0.010733 -0.001927  0.007403  ...  0.032786 -0.045271  0.024262   \n",
       "3     -0.029980 -0.001456  0.053691  ...  0.001647 -0.011020 -0.015470   \n",
       "4     -0.010647 -0.001882  0.064441  ...  0.042877 -0.034219  0.020791   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "42439 -0.202724 -0.055616  0.250190  ...  0.069892 -0.027141  0.051759   \n",
       "42440  0.032711 -0.056100  0.225375  ...  0.104017 -0.082060  0.045554   \n",
       "42441  0.031075 -0.055574  0.407604  ...  0.156391 -0.055767  0.058176   \n",
       "42442  0.040132 -0.056104  0.356369  ...  0.086769 -0.134194  0.059559   \n",
       "42443  0.042462 -0.055821  0.534847  ...  0.342058 -0.100431  0.058591   \n",
       "\n",
       "           1894      1895      1896      1897      1898      1899  class  \n",
       "0     -0.140464 -0.159461  0.172770  0.038176  0.001045  0.130533      0  \n",
       "1     -0.146390 -0.160165  0.184182  0.034579 -0.002108  0.113139      0  \n",
       "2     -0.131867 -0.132735  0.214412  0.028494 -0.030600  0.124883      0  \n",
       "3     -0.157489 -0.096212  0.107507  0.021454  0.144605  0.038405      0  \n",
       "4     -0.033644 -0.042421  0.006428  0.064086  0.299079  0.020408      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "42439  0.039957  0.024313  0.275040  0.092340  0.051801  0.044719      1  \n",
       "42440  0.038322  0.016898  0.088050  0.076477  0.074435  0.124462      1  \n",
       "42441  0.037907  0.035981  0.115794  0.084910  0.052877  0.029546      1  \n",
       "42442  0.012348  0.013011  0.087329  0.049971  0.085940  0.047609      1  \n",
       "42443  0.045007  0.042174  0.047897  0.121984  0.111572  0.031473      1  \n",
       "\n",
       "[41951 rows x 1901 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMPs_df.drop_duplicates(subset=['Sequence'],inplace=True)\n",
    "df =AMPs_df[[\"reps\",\"class\"]]\n",
    "df\n",
    "df_new = df.reps.apply(pd.Series).astype(np.float64)\n",
    "df_new['class'] = df['class']\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.iloc[:,:-1]\n",
    "y = df_new.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RFclassifier = RandomForestClassifier ( random_state=42)\n",
    "RFclassifier.fit(X_train, y_train)\n",
    "y_pred = RFclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      4335\n",
      "           1       0.90      0.91      0.91      4056\n",
      "\n",
      "    accuracy                           0.91      8391\n",
      "   macro avg       0.91      0.91      0.91      8391\n",
      "weighted avg       0.91      0.91      0.91      8391\n",
      "\n",
      "0.9094267667739244\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_Matrix(classifier, X_test, y_test):\n",
    "    class_names = ['AMPs', 'NonAMPs']\n",
    "\n",
    "    disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "                                display_labels = class_names,\n",
    "                                cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "\n",
    "    disp.ax_.set_title(\" Confusion Matrix\")\n",
    "\n",
    "    print(disp.confusion_matrix)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(AMPs_df['reps'].to_list())\n",
    "y= np.array(AMPs_df['class'].to_list())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFclassifier = RandomForestClassifier ( random_state=42)\n",
    "RFclassifier.fit(X_train, y_train)\n",
    "y_pred = RFclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      8873\n",
      "           1       0.90      0.92      0.91      8866\n",
      "\n",
      "    accuracy                           0.91     17739\n",
      "   macro avg       0.91      0.91      0.91     17739\n",
      "weighted avg       0.91      0.91      0.91     17739\n",
      "\n",
      "0.9093522746490783\n",
      "[[7963  910]\n",
      " [ 698 8168]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "confusion_Matrix(RFclassifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_RF.model', 'wb') as f:\n",
    "    pickle.dump(RFclassifier, f)\n",
    "#RFclassifier.save_model( \"best_RF.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1724c8490d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m scores = cross_validate(\n\u001b[0;32m----> 4\u001b[0;31m     RFclassifier, X_test, y_test, scoring=scoring, cv=kfold, return_train_score=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m print(\"Accuracy TEST: %0.2f (+/- %0.2f) Accuracy TRAIN: %0.2f (+/- %0.2f)\" %\n\u001b[1;32m      6\u001b[0m       (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2, scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 248\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 392\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "scoring = ['accuracy', 'f1', 'roc_auc', 'recall', 'precision','neg_log_loss']\n",
    "scores = cross_validate(\n",
    "    RFclassifier, X_test, y_test, scoring=scoring, cv=kfold, return_train_score=True)\n",
    "print(\"Accuracy TEST: %0.2f (+/- %0.2f) Accuracy TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2, scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
    "print(\"F1 TEST: %0.2f (+/- %0.2f) F1 TRAIN : %0.2f (+/- %0.2f) \" %\n",
    "      (scores['test_f1'].mean(), scores['test_f1'].std() * 2, scores['train_f1'].mean(), scores['train_f1'].std() * 2))\n",
    "print(\"AUROC TEST: %0.2f (+/- %0.2f) AUROC TRAIN : %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_roc_auc'].mean(), scores['test_roc_auc'].std() * 2, scores['train_roc_auc'].mean(), scores['train_roc_auc'].std() * 2))\n",
    "print(\"recall TEST: %0.2f (+/- %0.2f) recall TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_recall'].mean(), scores['test_recall'].std() * 2, scores['train_recall'].mean(), scores['train_recall'].std() * 2))\n",
    "print(\"Precision TEST: %0.2f (+/- %0.2f) Precision TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_precision'].mean(), scores['test_precision'].std() * 2, scores['train_precision'].mean(), scores['train_precision'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
