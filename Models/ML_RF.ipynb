{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection  import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "with open( \"/mnt/vdb/thesis/jax/AMPNonAMP.V4_sim95.reps\", 'rb') as file:\n",
    "    AMPs_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1891</th>\n",
       "      <th>1892</th>\n",
       "      <th>1893</th>\n",
       "      <th>1894</th>\n",
       "      <th>1895</th>\n",
       "      <th>1896</th>\n",
       "      <th>1897</th>\n",
       "      <th>1898</th>\n",
       "      <th>1899</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.073286</td>\n",
       "      <td>0.039610</td>\n",
       "      <td>-0.081396</td>\n",
       "      <td>-0.097664</td>\n",
       "      <td>-0.009299</td>\n",
       "      <td>0.141095</td>\n",
       "      <td>-0.014705</td>\n",
       "      <td>-0.002360</td>\n",
       "      <td>0.017338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038974</td>\n",
       "      <td>-0.041898</td>\n",
       "      <td>0.014611</td>\n",
       "      <td>-0.140464</td>\n",
       "      <td>-0.159461</td>\n",
       "      <td>0.172770</td>\n",
       "      <td>0.038176</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.130533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.069160</td>\n",
       "      <td>0.034436</td>\n",
       "      <td>-0.074240</td>\n",
       "      <td>-0.091777</td>\n",
       "      <td>-0.012302</td>\n",
       "      <td>0.129554</td>\n",
       "      <td>-0.013877</td>\n",
       "      <td>-0.002370</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032007</td>\n",
       "      <td>-0.053930</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>-0.146390</td>\n",
       "      <td>-0.160165</td>\n",
       "      <td>0.184182</td>\n",
       "      <td>0.034579</td>\n",
       "      <td>-0.002108</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.054063</td>\n",
       "      <td>0.029643</td>\n",
       "      <td>-0.077715</td>\n",
       "      <td>-0.102382</td>\n",
       "      <td>-0.018419</td>\n",
       "      <td>0.130293</td>\n",
       "      <td>-0.010733</td>\n",
       "      <td>-0.001927</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032786</td>\n",
       "      <td>-0.045271</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>-0.131867</td>\n",
       "      <td>-0.132735</td>\n",
       "      <td>0.214412</td>\n",
       "      <td>0.028494</td>\n",
       "      <td>-0.030600</td>\n",
       "      <td>0.124883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.071879</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>-0.062474</td>\n",
       "      <td>-0.208573</td>\n",
       "      <td>-0.070853</td>\n",
       "      <td>0.098093</td>\n",
       "      <td>-0.029980</td>\n",
       "      <td>-0.001456</td>\n",
       "      <td>0.053691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>-0.011020</td>\n",
       "      <td>-0.015470</td>\n",
       "      <td>-0.157489</td>\n",
       "      <td>-0.096212</td>\n",
       "      <td>0.107507</td>\n",
       "      <td>0.021454</td>\n",
       "      <td>0.144605</td>\n",
       "      <td>0.038405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>0.042706</td>\n",
       "      <td>-0.037508</td>\n",
       "      <td>-0.253113</td>\n",
       "      <td>-0.006857</td>\n",
       "      <td>-0.145191</td>\n",
       "      <td>-0.010647</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>0.064441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042877</td>\n",
       "      <td>-0.034219</td>\n",
       "      <td>0.020791</td>\n",
       "      <td>-0.033644</td>\n",
       "      <td>-0.042421</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.064086</td>\n",
       "      <td>0.299079</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42439</th>\n",
       "      <td>0.047398</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>-0.039842</td>\n",
       "      <td>0.050582</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>0.068586</td>\n",
       "      <td>-0.219056</td>\n",
       "      <td>-0.202724</td>\n",
       "      <td>-0.055616</td>\n",
       "      <td>0.250190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069892</td>\n",
       "      <td>-0.027141</td>\n",
       "      <td>0.051759</td>\n",
       "      <td>0.039957</td>\n",
       "      <td>0.024313</td>\n",
       "      <td>0.275040</td>\n",
       "      <td>0.092340</td>\n",
       "      <td>0.051801</td>\n",
       "      <td>0.044719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42440</th>\n",
       "      <td>0.048349</td>\n",
       "      <td>-0.007824</td>\n",
       "      <td>-0.033272</td>\n",
       "      <td>0.051004</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>0.054971</td>\n",
       "      <td>-0.509455</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>-0.056100</td>\n",
       "      <td>0.225375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104017</td>\n",
       "      <td>-0.082060</td>\n",
       "      <td>0.045554</td>\n",
       "      <td>0.038322</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>0.088050</td>\n",
       "      <td>0.076477</td>\n",
       "      <td>0.074435</td>\n",
       "      <td>0.124462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42441</th>\n",
       "      <td>0.047338</td>\n",
       "      <td>-0.013988</td>\n",
       "      <td>-0.038846</td>\n",
       "      <td>0.051135</td>\n",
       "      <td>0.025912</td>\n",
       "      <td>0.071711</td>\n",
       "      <td>-0.449391</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>-0.055574</td>\n",
       "      <td>0.407604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156391</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>0.058176</td>\n",
       "      <td>0.037907</td>\n",
       "      <td>0.035981</td>\n",
       "      <td>0.115794</td>\n",
       "      <td>0.084910</td>\n",
       "      <td>0.052877</td>\n",
       "      <td>0.029546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42442</th>\n",
       "      <td>0.046977</td>\n",
       "      <td>-0.027571</td>\n",
       "      <td>-0.030715</td>\n",
       "      <td>0.050779</td>\n",
       "      <td>-0.116802</td>\n",
       "      <td>0.074466</td>\n",
       "      <td>-0.375273</td>\n",
       "      <td>0.040132</td>\n",
       "      <td>-0.056104</td>\n",
       "      <td>0.356369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086769</td>\n",
       "      <td>-0.134194</td>\n",
       "      <td>0.059559</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>0.013011</td>\n",
       "      <td>0.087329</td>\n",
       "      <td>0.049971</td>\n",
       "      <td>0.085940</td>\n",
       "      <td>0.047609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42443</th>\n",
       "      <td>0.047497</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>-0.033763</td>\n",
       "      <td>0.051256</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>-0.575566</td>\n",
       "      <td>0.042462</td>\n",
       "      <td>-0.055821</td>\n",
       "      <td>0.534847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342058</td>\n",
       "      <td>-0.100431</td>\n",
       "      <td>0.058591</td>\n",
       "      <td>0.045007</td>\n",
       "      <td>0.042174</td>\n",
       "      <td>0.047897</td>\n",
       "      <td>0.121984</td>\n",
       "      <td>0.111572</td>\n",
       "      <td>0.031473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41951 rows × 1901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.003220  0.073286  0.039610 -0.081396 -0.097664 -0.009299  0.141095   \n",
       "1      0.002793  0.069160  0.034436 -0.074240 -0.091777 -0.012302  0.129554   \n",
       "2      0.002317  0.054063  0.029643 -0.077715 -0.102382 -0.018419  0.130293   \n",
       "3      0.014645  0.071879  0.034763 -0.062474 -0.208573 -0.070853  0.098093   \n",
       "4      0.006236  0.018485  0.042706 -0.037508 -0.253113 -0.006857 -0.145191   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "42439  0.047398  0.019436 -0.039842  0.050582  0.031774  0.068586 -0.219056   \n",
       "42440  0.048349 -0.007824 -0.033272  0.051004  0.013359  0.054971 -0.509455   \n",
       "42441  0.047338 -0.013988 -0.038846  0.051135  0.025912  0.071711 -0.449391   \n",
       "42442  0.046977 -0.027571 -0.030715  0.050779 -0.116802  0.074466 -0.375273   \n",
       "42443  0.047497  0.005815 -0.033763  0.051256  0.012093  0.054598 -0.575566   \n",
       "\n",
       "              7         8         9  ...      1891      1892      1893  \\\n",
       "0     -0.014705 -0.002360  0.017338  ...  0.038974 -0.041898  0.014611   \n",
       "1     -0.013877 -0.002370  0.006206  ...  0.032007 -0.053930  0.010304   \n",
       "2     -0.010733 -0.001927  0.007403  ...  0.032786 -0.045271  0.024262   \n",
       "3     -0.029980 -0.001456  0.053691  ...  0.001647 -0.011020 -0.015470   \n",
       "4     -0.010647 -0.001882  0.064441  ...  0.042877 -0.034219  0.020791   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "42439 -0.202724 -0.055616  0.250190  ...  0.069892 -0.027141  0.051759   \n",
       "42440  0.032711 -0.056100  0.225375  ...  0.104017 -0.082060  0.045554   \n",
       "42441  0.031075 -0.055574  0.407604  ...  0.156391 -0.055767  0.058176   \n",
       "42442  0.040132 -0.056104  0.356369  ...  0.086769 -0.134194  0.059559   \n",
       "42443  0.042462 -0.055821  0.534847  ...  0.342058 -0.100431  0.058591   \n",
       "\n",
       "           1894      1895      1896      1897      1898      1899  class  \n",
       "0     -0.140464 -0.159461  0.172770  0.038176  0.001045  0.130533      0  \n",
       "1     -0.146390 -0.160165  0.184182  0.034579 -0.002108  0.113139      0  \n",
       "2     -0.131867 -0.132735  0.214412  0.028494 -0.030600  0.124883      0  \n",
       "3     -0.157489 -0.096212  0.107507  0.021454  0.144605  0.038405      0  \n",
       "4     -0.033644 -0.042421  0.006428  0.064086  0.299079  0.020408      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "42439  0.039957  0.024313  0.275040  0.092340  0.051801  0.044719      1  \n",
       "42440  0.038322  0.016898  0.088050  0.076477  0.074435  0.124462      1  \n",
       "42441  0.037907  0.035981  0.115794  0.084910  0.052877  0.029546      1  \n",
       "42442  0.012348  0.013011  0.087329  0.049971  0.085940  0.047609      1  \n",
       "42443  0.045007  0.042174  0.047897  0.121984  0.111572  0.031473      1  \n",
       "\n",
       "[41951 rows x 1901 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMPs_df.drop_duplicates(subset=['Sequence'],inplace=True)\n",
    "df =AMPs_df[[\"reps\",\"class\"]]\n",
    "df\n",
    "df_new = df.reps.apply(pd.Series).astype(np.float64)\n",
    "df_new['class'] = df['class']\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.iloc[:,:-1]\n",
    "y = df_new.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RFclassifier = RandomForestClassifier ( random_state=42)\n",
    "RFclassifier.fit(X_train, y_train)\n",
    "y_pred = RFclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      4335\n",
      "           1       0.90      0.91      0.91      4056\n",
      "\n",
      "    accuracy                           0.91      8391\n",
      "   macro avg       0.91      0.91      0.91      8391\n",
      "weighted avg       0.91      0.91      0.91      8391\n",
      "\n",
      "0.9094267667739244\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_Matrix(classifier, X_test, y_test):\n",
    "    class_names = ['AMPs', 'NonAMPs']\n",
    "\n",
    "    disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "                                display_labels = class_names,\n",
    "                                cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "\n",
    "    disp.ax_.set_title(\" Confusion Matrix\")\n",
    "\n",
    "    print(disp.confusion_matrix)\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X= np.array(AMPs_df['reps'].to_list())\n",
    "#y= np.array(AMPs_df['class'].to_list())\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(AMPs_df['reps'].to_list()), np.array(AMPs_df['class'].to_list()), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFclassifier = RandomForestClassifier ( random_state=42)\n",
    "RFclassifier.fit(X_train, y_train)\n",
    "y_pred = RFclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94     21297\n",
      "           1       0.93      0.95      0.94     21559\n",
      "\n",
      "    accuracy                           0.94     42856\n",
      "   macro avg       0.94      0.94      0.94     42856\n",
      "weighted avg       0.94      0.94      0.94     42856\n",
      "\n",
      "0.9372083255553482\n",
      "[[19654  1643]\n",
      " [ 1048 20511]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "confusion_Matrix(RFclassifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/vdb/thesis/best_RF.model', 'wb') as f:\n",
    "    pickle.dump(RFclassifier, f)\n",
    "#RFclassifier.save_model( \"best_RF.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1724c8490d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m scores = cross_validate(\n\u001b[0;32m----> 4\u001b[0;31m     RFclassifier, X_test, y_test, scoring=scoring, cv=kfold, return_train_score=True)\n\u001b[0m\u001b[1;32m      5\u001b[0m print(\"Accuracy TEST: %0.2f (+/- %0.2f) Accuracy TRAIN: %0.2f (+/- %0.2f)\" %\n\u001b[1;32m      6\u001b[0m       (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2, scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 248\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 392\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "scoring = ['accuracy', 'f1', 'roc_auc', 'recall', 'precision','neg_log_loss']\n",
    "scores = cross_validate(\n",
    "    RFclassifier, X_test, y_test, scoring=scoring, cv=kfold, return_train_score=True)\n",
    "print(\"Accuracy TEST: %0.2f (+/- %0.2f) Accuracy TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_accuracy'].mean(), scores['test_accuracy'].std() * 2, scores['train_accuracy'].mean(), scores['train_accuracy'].std() * 2))\n",
    "print(\"F1 TEST: %0.2f (+/- %0.2f) F1 TRAIN : %0.2f (+/- %0.2f) \" %\n",
    "      (scores['test_f1'].mean(), scores['test_f1'].std() * 2, scores['train_f1'].mean(), scores['train_f1'].std() * 2))\n",
    "print(\"AUROC TEST: %0.2f (+/- %0.2f) AUROC TRAIN : %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_roc_auc'].mean(), scores['test_roc_auc'].std() * 2, scores['train_roc_auc'].mean(), scores['train_roc_auc'].std() * 2))\n",
    "print(\"recall TEST: %0.2f (+/- %0.2f) recall TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_recall'].mean(), scores['test_recall'].std() * 2, scores['train_recall'].mean(), scores['train_recall'].std() * 2))\n",
    "print(\"Precision TEST: %0.2f (+/- %0.2f) Precision TRAIN: %0.2f (+/- %0.2f)\" %\n",
    "      (scores['test_precision'].mean(), scores['test_precision'].std() * 2, scores['train_precision'].mean(), scores['train_precision'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
