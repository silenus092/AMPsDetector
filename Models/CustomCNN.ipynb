{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48641189/fitting-3d-data-as-input-into-keras-sequential-model-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qhoptim\n",
      "  Downloading qhoptim-1.1.0-py3-none-any.whl (20 kB)\n",
      "\u001b[33mWARNING: Error parsing requirements for matplotlib: [Errno 2] No such file or directory: '/home/ubuntu/miniconda3/envs/py3/lib/python3.7/site-packages/matplotlib-3.3.2.dist-info/METADATA'\u001b[0m\n",
      "Installing collected packages: qhoptim\n",
      "Successfully installed qhoptim-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install qhoptim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.3\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ubuntu/miniconda3/envs/py3\n",
      "\n",
      "  added / updated specs:\n",
      "    - keras=2.3.1\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2020.12.5          |   py37h06a4308_0         141 KB\n",
      "    keras-2.3.1                |                0          12 KB\n",
      "    keras-base-2.3.1           |           py37_0         495 KB\n",
      "    openssl-1.1.1i             |       h27cfd23_0         2.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  keras-base         pkgs/main/linux-64::keras-base-2.3.1-py37_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2020.12.~ --> pkgs/main::ca-certificates-2021.1.19-h06a4308_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge::certifi-2020.12.5-py37h8~ --> pkgs/main::certifi-2020.12.5-py37h06a4308_0\n",
      "  keras                conda-forge/noarch::keras-2.4.3-py_0 --> pkgs/main/linux-64::keras-2.3.1-0\n",
      "  openssl            conda-forge::openssl-1.1.1i-h7f98852_0 --> pkgs/main::openssl-1.1.1i-h27cfd23_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.1.1i       | 2.5 MB    | ##################################### | 100% \n",
      "keras-base-2.3.1     | 495 KB    | ##################################### | 100% \n",
      "keras-2.3.1          | 12 KB     | ##################################### | 100% \n",
      "certifi-2020.12.5    | 141 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install keras=2.3.1 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Use only CPU\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17993022828398494510\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3274618457875477408\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 4232872575163048890\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 31595870336\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5370779830014107259\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:00:06.0, compute capability: 7.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4aBzk8QXHS9S"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "from IPython.display import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "#keras\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2, l1_l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv1D, Add, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, GlobalMaxPooling1D, AveragePooling1D, GlobalAveragePooling1D\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# CuDNNLSTM error; The error was because from TensorFlow 2 you do not need to specify CuDNNLSTM. \n",
    "# You can just use LSTM with no activation function and it will automatically use the CuDNN version. You do have to install CuDNN first.\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# \n",
    "from qhoptim.tf import QHAdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Optimizer\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "class QHAdam(Optimizer):\n",
    "    \"\"\"QH-Adam optimizer.\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta_1 < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta_2 < 1. Generally close to 1.\n",
    "        neu_1: float, 0 < neu_1 < 1. Default based on paper equals 0.7\n",
    "        neu_2: float, 0 < neu_2 < 1. Default based on paper equals 1\n",
    "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
    "            algorithm from the paper \"On the Convergence of Adam and\n",
    "            Beyond\".\n",
    "    # References\n",
    "        - [QUASI-HYPERBOLIC MOMENTUM AND ADAM FOR DEEP LEARNING](\n",
    "           https://openreview.net/pdf?id=S1fUpoR5FQ)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 lr=0.001,\n",
    "                 beta_1=0.999,\n",
    "                 beta_2=0.999,\n",
    "                 neu_1 = 0.7,\n",
    "                 neu_2 = 1.,\n",
    "                 epsilon=1e-3,\n",
    "                 decay=0.,\n",
    "                 amsgrad=False,\n",
    "                 **kwargs):\n",
    "        super(QHAdam, self).__init__(name=\"QHAdam\",**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.learning_rate = K.variable(lr, name='lr')\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
    "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
    "            self.neu_1 = K.variable(neu_1, name='neu_1')\n",
    "            self.neu_2 = K.variable(neu_2, name='neu_2')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "        if epsilon is None:\n",
    "            epsilon = K.epsilon()\n",
    "        self.epsilon = epsilon\n",
    "        self.initial_decay = decay\n",
    "        self.amsgrad = amsgrad\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.learning_rate\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                      K.dtype(self.decay))))\n",
    "\n",
    "        t = K.cast(self.iterations, K.floatx()) + 1\n",
    "\n",
    "\n",
    "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        if self.amsgrad:\n",
    "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
    "        else:\n",
    "            vhats = [K.zeros(1) for _ in params]\n",
    "        self.weights = [self.iterations] + ms + vs + vhats\n",
    "\n",
    "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            m_t_adj = m_t/(1. - K.pow(self.beta_1, t))\n",
    "            v_t_adj = v_t/(1. - K.pow(self.beta_2, t))\n",
    "            if self.amsgrad:\n",
    "                vhat_t = K.maximum(vhat, v_t)\n",
    "                p_t = p - lr * ((1.- self.neu_1)*g + self.neu_1*(m_t_adj)) / \\\n",
    "                       (K.sqrt((1.-self.neu_2) * K.square(g) + self.neu_2 * vhat_t) + self.epsilon)\n",
    "                self.updates.append(K.update(vhat, vhat_t))\n",
    "            else:\n",
    "                p_t = p - lr * ((1.-self.neu_1)*g + self.neu_1*(m_t_adj)) / \\\n",
    "                       (K.sqrt((1.-self.neu_2)*K.square(g) + self.neu_2 * v_t_adj) + self.epsilon)\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "            new_p = p_t\n",
    "\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.learning_rate)),\n",
    "                  'beta_1': float(K.get_value(self.beta_1)),\n",
    "                  'beta_2': float(K.get_value(self.beta_2)),\n",
    "                  'neu_1': float(K.get_value(self.neu_1)),\n",
    "                  'neu_2': float(K.get_value(self.neu_2)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'epsilon': self.epsilon,\n",
    "                  'amsgrad': self.amsgrad}\n",
    "        base_config = super(QHAdam, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FNhtXHJrfEE4"
   },
   "outputs": [],
   "source": [
    "# small old ../datasets/AMPsNonAMPs_df.239.plk\n",
    "# /home/ubuntu/data/AMPsNonAMPs_df.plk old dataset\n",
    "# /mnt/vdb/thesis/jax/AMPNonAMP.final.reps new dataset\n",
    "import pickle5 as pickle\n",
    "with open( \"/mnt/vdb/thesis/jax/AMPNonAMP.V4_sim95.reps\", 'rb') as file:\n",
    "    AMPs_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "mGiMSzzPfj2t",
    "outputId": "092eb611-b89c-4cac-c8c4-0557799510cf"
   },
   "outputs": [],
   "source": [
    "#AMPs_df.drop_duplicates(subset=['Sequence'],inplace=True)\n",
    "AMPs_df =AMPs_df[AMPs_df[\"length\"] <=30 ]\n",
    "AMPs_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2i7Tk41aDZ5"
   },
   "source": [
    "### Utility function: plot_history, display_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7F7ykQsDVxHO"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  # dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  x = range(1, len(acc) + 1)\n",
    "\n",
    "  plt.figure(figsize=(12, 5))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.plot(x, acc, 'b', label='Training acc')\n",
    "  plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(x, loss, 'b', label='Training loss')\n",
    "  plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.legend()\n",
    "\n",
    "# Display model score(Loss & Accuracy) across all sets.\n",
    "def display_model_score(model, train, val, test):\n",
    "  train_score = model.evaluate(train[0], train[1], verbose=1)\n",
    "  print('Train loss: ', train_score[0])\n",
    "  print('Train accuracy: ', train_score[1])\n",
    "  print('-'*70)\n",
    "  val_score = model.evaluate(val[0], val[1], verbose=1)\n",
    "  print('Val loss: ', val_score[0])\n",
    "  print('Val accuracy: ', val_score[1])\n",
    "  print('-'*70)\n",
    "  test_score = model.evaluate(test[0], test[1], verbose=1)\n",
    "  print('Test loss: ', test_score[0])\n",
    "  print('Test accuracy: ', test_score[1])\n",
    "\n",
    "def plot_history_CV(cv, estimator,x,y):\n",
    "  # plot arrows\n",
    "  fig1 = plt.figure(figsize=[12,12])\n",
    "  ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
    "  ax1.add_patch(\n",
    "      patches.Arrow(0.45,0.5,-0.25,0.25,width=0.3,color='green',alpha = 0.5)\n",
    "      )\n",
    "  ax1.add_patch(\n",
    "      patches.Arrow(0.5,0.45,0.25,-0.25,width=0.3,color='red',alpha = 0.5)\n",
    "      )\n",
    "\n",
    "  tprs = []\n",
    "  aucs = []\n",
    "  mean_fpr = np.linspace(0,1,100)\n",
    "  i = 1\n",
    "  for train,test in cv.split(x,y):\n",
    "      model = create_Modelbaseline()\n",
    "      model.fit(x[train],y.iloc[train],\n",
    "            epochs=30,\n",
    "            shuffle=True,verbose=0)\n",
    "      prediction = model.predict(x[test])\n",
    "      fpr, tpr, t = roc_curve(y[test], prediction[:, 1])\n",
    "      tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "      roc_auc = auc(fpr, tpr)\n",
    "      aucs.append(roc_auc)\n",
    "      plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "      i= i+1\n",
    "\n",
    "  plt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\n",
    "  mean_tpr = np.mean(tprs, axis=0)\n",
    "  mean_auc = auc(mean_fpr, mean_tpr)\n",
    "  plt.plot(mean_fpr, mean_tpr, color='blue',\n",
    "          label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n",
    "\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.title('ROC')\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  plt.text(0.32,0.7,'More accurate area',fontsize = 12)\n",
    "  plt.text(0.63,0.4,'Less accurate area',fontsize = 12)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI-_ZAvfIb5A"
   },
   "source": [
    "# Split Train/ Test / Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lAAQLx4UIptD"
   },
   "outputs": [],
   "source": [
    "#X= np.array(AMPs_df['reps'].to_list())\n",
    "#y= np.array(AMPs_df['class'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EkmqGqfUT0XR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2b78aed1e0f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_shape\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "input_shape  = X.shape\n",
    "input_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UWQ2IZWgIbST"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(AMPs_df['reps'].to_list()),  np.array(AMPs_df['class'].to_list()), test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "IM7Scdevkwpp",
    "outputId": "55fa7ea6-a5f9-4e23-bf42-f1a4bf64f8a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  128565\n",
      "Val size:  42855\n",
      "Test size:  42856\n"
     ]
    }
   ],
   "source": [
    "# Given data size\n",
    "print('Train size: ', len(X_train))\n",
    "print('Val size: ', len(X_val))\n",
    "print('Test size: ', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128565, 1900, 1)\n",
      "(42856, 1900, 1)\n",
      "(42855, 1900, 1)\n"
     ]
    }
   ],
   "source": [
    "# 3d dimension for LSTM\n",
    "# Batchs, n_timesteps, n_features\n",
    "\n",
    "# Images 3d dimension\n",
    "# width , heigth , channel\n",
    "\n",
    "# Conv1D with sequential data\n",
    "# batch, steps, channels\n",
    "\n",
    "# https://stackoverflow.com/questions/52803989/how-to-correct-shape-of-keras-input-into-a-3d-array/52804200\n",
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
    "print(X_train.shape)\n",
    "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
    "print(X_test.shape)\n",
    "X_val = np.reshape(X_val,(X_val.shape[0],X_val.shape[1],1))\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1900, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1900, 512)         4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 633, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 633, 256)          655616    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 316, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 80896)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1211)              97966267  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1211)              1467732   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 1212      \n",
      "=================================================================\n",
      "Total params: 100,094,923\n",
      "Trainable params: 100,094,923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the best Mark I\n",
    "def create_Modelbaseline():\n",
    "    x_input = Input(shape=(1900,1)) # n_timesteps, n_features\n",
    "    # Conv\n",
    "    conv = Conv1D(512, kernel_size=7, strides=1, padding='same', activation='relu')(x_input) \n",
    "    conv = MaxPooling1D(pool_size=3)(conv)\n",
    "    conv = Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu')(conv) \n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "\n",
    "    # Flatten NN\n",
    "    flat = Flatten()(conv)\n",
    "    \n",
    "    layer_3 = Dense(2432, activation='relu')(flat)\n",
    "    dropout_3 = Dropout(0.5)(layer_3)\n",
    "    layer_4 = Dense(1211, activation='relu')(dropout_3)\n",
    "    dropout_4 = Dropout(0.5)(layer_4)\n",
    "    x_output = Dense(1, activation='sigmoid', name='output_layer', kernel_regularizer=l2(0.0001))(dropout_4)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=x_output)\n",
    "    model.compile(optimizer=\"RMSprop\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_Modelbaseline()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 1900, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 1900, 512)         4608      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 633, 512)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 633, 256)          655616    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 316, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 80896)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1211)              97966267  \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1211)              1467732   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 1212      \n",
      "=================================================================\n",
      "Total params: 100,095,435\n",
      "Trainable params: 100,095,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# n_timesteps, n_features, n_outputs = X_train.shape[2], X_train.shape[1], 1\n",
    "# nn.Conv1d with a kernel size of 1 and nn.Linear   give exactly the same results.\n",
    "\n",
    "# use in dev \n",
    "\n",
    "#SGD\n",
    "#RMSprop\n",
    "#Adam\n",
    "#Adadelta\n",
    "#Adagrad\n",
    "#Adamax\n",
    "#Nadam\n",
    "#Ftrl\n",
    "#\n",
    "#\n",
    "def create_Modelbaseline():\n",
    "    x_input = Input(shape=(1900,1)) # n_timesteps, n_features\n",
    "    # Conv\n",
    "    #conv = Conv1D(512, kernel_size=7, strides=1, padding='same', activation='relu')(x_input) \n",
    "    #conv = MaxPooling1D(pool_size=3)(conv)\n",
    "    conv = Conv1D(512, kernel_size=8, strides=1, padding='same', activation='relu')(x_input) \n",
    "    conv = MaxPooling1D(pool_size=3)(conv)\n",
    "    dropout_3 = Dropout(0.5)(layer_3)\n",
    "    conv = Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu')(conv) \n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    dropout_3 = Dropout(0.5)(layer_3)\n",
    "   \n",
    "    # Flatten NN\n",
    "    flat = Flatten()(conv)\n",
    "    layer_3 = Dense(1211, activation='relu')(flat)\n",
    "    dropout_3 = Dropout(0.2)(layer_3)\n",
    "    layer_4 = Dense(1211, activation='relu')(dropout_3)\n",
    "    dropout_4 = Dropout(0.2)(layer_4)\n",
    "    x_output = Dense(1, activation='sigmoid', name='output_layer', kernel_regularizer=l2(0.0001))(dropout_4)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=x_output)\n",
    "    model.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_Modelbaseline()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1900, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1900, 64)          3264      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 63, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 63, 128)           155776    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 6, 128)            512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1211)              931259    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               620544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,711,868\n",
      "Trainable params: 1,711,612\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create_ModelII\n",
    "## https://github.com/p-koo/learning_sequence_motifs/blob/master/code/models/cnn_25.py show best here \n",
    "def create_Modelbaseline():\n",
    "    x_input = Input(shape=(1900,1)) # n_timesteps, n_features\n",
    "    # Conv\n",
    "  #bn1 = BatchNormalization()(data)\n",
    "  #act1 = Activation('relu')(bn1)\n",
    "    \n",
    "    conv = Conv1D(64, kernel_size=19, strides=1, padding='same', activation='relu')(x_input)  # Extract whole motif pattern\n",
    "    conv = MaxPooling1D(pool_size=25)(conv)\n",
    "    conv = Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu')(conv)  # Extract extra features  \n",
    "    conv = MaxPooling1D(pool_size=4)(conv)\n",
    "    \n",
    "    x = BatchNormalization()(conv)\n",
    "   \n",
    "    # Flatten NN\n",
    "    flat = Flatten()(x)\n",
    "    layer_3 = Dense(1211, activation='relu')(flat)\n",
    "    dropout_3 = Dropout(0.5)(layer_3)\n",
    "    layer_4 = Dense(512, activation='relu')(dropout_3)\n",
    "    dropout_4 = Dropout(0.5)(layer_4)\n",
    "    x_output = Dense(1, activation='sigmoid', name='output_layer', kernel_regularizer=l1_l2(0.000001))(dropout_4)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=x_output)\n",
    "    model.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_Modelbaseline()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1900, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1900, 64)          2624      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 76, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 76, 128)           57472     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 19, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 19, 128)           512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1211)              2946363   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1211)              4844      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1211)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               620544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,634,920\n",
      "Trainable params: 3,631,218\n",
      "Non-trainable params: 3,702\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create_ModelIII\n",
    "#\n",
    "\n",
    "def create_Modelbaseline():\n",
    "    x_input = Input(shape=(1900,1)) # n_timesteps, n_features\n",
    "        \n",
    "    conv = Conv1D(64, kernel_size=40, strides=1, padding='same', activation='relu')(x_input)  # Extract whole motif pattern\n",
    "    conv = MaxPooling1D(pool_size=25)(conv)\n",
    "    conv = Conv1D(128, kernel_size=7, strides=1, padding='same', activation='relu')(conv)  # Extract extra features  \n",
    "    conv = MaxPooling1D(pool_size=4)(conv)\n",
    "    \n",
    "    x = BatchNormalization()(conv)\n",
    "    x = Flatten()(x)\n",
    "    #output = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    output = Dense(2432, activation=None)(x)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Activation('relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    \n",
    "    output = Dense(1216, activation=None)(output)\n",
    "    output = BatchNormalization()(output)\n",
    "    output = Activation('relu')(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    \n",
    "    output = Flatten()(output)\n",
    "    x_output = Dense(1, activation='sigmoid', name='output_layer', kernel_regularizer=l1_l2(0.000001))(output)\n",
    "    model = Model(inputs=x_input, outputs=x_output)\n",
    "    model.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_Modelbaseline()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras import backend as K\n",
    "#K.set_value(model_ProtCNN.optimizer.learning_rate, 0.00001)\n",
    "def lr_schedule(epoch):\n",
    "    \n",
    "    lr = 1e-3\n",
    "    if epoch > 80:\n",
    "        lr = 0.1e-6\n",
    "    elif epoch > 50:    \n",
    "        lr = 0.3e-5\n",
    "    elif epoch > 20:\n",
    "        lr = 1e-4\n",
    "        \n",
    "    print(' Learning rate: ', lr)    \n",
    "    return lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      " Learning rate:  0.001\n",
      "Epoch 1/100\n",
      "1005/1005 [==============================] - 9s 9ms/step - loss: 0.2960 - accuracy: 0.8797 - val_loss: 0.7383 - val_accuracy: 0.6584\n",
      " Learning rate:  0.001\n",
      "Epoch 2/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.2203 - accuracy: 0.9142 - val_loss: 0.3606 - val_accuracy: 0.8430\n",
      " Learning rate:  0.001\n",
      "Epoch 3/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1980 - accuracy: 0.9234 - val_loss: 0.2516 - val_accuracy: 0.9000\n",
      " Learning rate:  0.001\n",
      "Epoch 4/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1840 - accuracy: 0.9298 - val_loss: 0.1947 - val_accuracy: 0.9239\n",
      " Learning rate:  0.001\n",
      "Epoch 5/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1725 - accuracy: 0.9356 - val_loss: 0.2364 - val_accuracy: 0.9031\n",
      " Learning rate:  0.001\n",
      "Epoch 6/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1629 - accuracy: 0.9381 - val_loss: 0.2206 - val_accuracy: 0.9109\n",
      " Learning rate:  0.001\n",
      "Epoch 7/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1569 - accuracy: 0.9405 - val_loss: 0.2199 - val_accuracy: 0.9135\n",
      " Learning rate:  0.001\n",
      "Epoch 8/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1482 - accuracy: 0.9442 - val_loss: 0.2176 - val_accuracy: 0.9099\n",
      " Learning rate:  0.001\n",
      "Epoch 9/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1473 - accuracy: 0.9445 - val_loss: 0.2726 - val_accuracy: 0.8909\n",
      " Learning rate:  0.001\n",
      "Epoch 10/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1397 - accuracy: 0.9474 - val_loss: 0.1694 - val_accuracy: 0.9367\n",
      " Learning rate:  0.001\n",
      "Epoch 11/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1339 - accuracy: 0.9492 - val_loss: 0.3559 - val_accuracy: 0.8447\n",
      " Learning rate:  0.001\n",
      "Epoch 12/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1286 - accuracy: 0.9516 - val_loss: 0.1803 - val_accuracy: 0.9345\n",
      " Learning rate:  0.001\n",
      "Epoch 13/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1228 - accuracy: 0.9534 - val_loss: 0.2026 - val_accuracy: 0.9243\n",
      " Learning rate:  0.001\n",
      "Epoch 14/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1182 - accuracy: 0.9556 - val_loss: 0.1689 - val_accuracy: 0.9390\n",
      " Learning rate:  0.001\n",
      "Epoch 15/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1142 - accuracy: 0.9571 - val_loss: 0.2444 - val_accuracy: 0.9049\n",
      " Learning rate:  0.001\n",
      "Epoch 16/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1083 - accuracy: 0.9593 - val_loss: 0.1947 - val_accuracy: 0.9293\n",
      " Learning rate:  0.001\n",
      "Epoch 17/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1056 - accuracy: 0.9601 - val_loss: 0.1865 - val_accuracy: 0.9324\n",
      " Learning rate:  0.001\n",
      "Epoch 18/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.1011 - accuracy: 0.9615 - val_loss: 0.1857 - val_accuracy: 0.9306\n",
      " Learning rate:  0.001\n",
      "Epoch 19/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0972 - accuracy: 0.9631 - val_loss: 0.2294 - val_accuracy: 0.9163\n",
      " Learning rate:  0.001\n",
      "Epoch 20/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0943 - accuracy: 0.9646 - val_loss: 0.2081 - val_accuracy: 0.9261\n",
      " Learning rate:  0.001\n",
      "Epoch 21/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0905 - accuracy: 0.9663 - val_loss: 0.1662 - val_accuracy: 0.9406\n",
      " Learning rate:  0.0001\n",
      "Epoch 22/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0647 - accuracy: 0.9765 - val_loss: 0.1700 - val_accuracy: 0.9476\n",
      " Learning rate:  0.0001\n",
      "Epoch 23/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0578 - accuracy: 0.9790 - val_loss: 0.1747 - val_accuracy: 0.9481\n",
      " Learning rate:  0.0001\n",
      "Epoch 24/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0545 - accuracy: 0.9805 - val_loss: 0.1800 - val_accuracy: 0.9483\n",
      " Learning rate:  0.0001\n",
      "Epoch 25/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0521 - accuracy: 0.9815 - val_loss: 0.1833 - val_accuracy: 0.9473\n",
      " Learning rate:  0.0001\n",
      "Epoch 26/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0506 - accuracy: 0.9820 - val_loss: 0.1826 - val_accuracy: 0.9473\n",
      " Learning rate:  0.0001\n",
      "Epoch 27/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0488 - accuracy: 0.9825 - val_loss: 0.1839 - val_accuracy: 0.9485\n",
      " Learning rate:  0.0001\n",
      "Epoch 28/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0465 - accuracy: 0.9836 - val_loss: 0.1877 - val_accuracy: 0.9475\n",
      " Learning rate:  0.0001\n",
      "Epoch 29/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0458 - accuracy: 0.9839 - val_loss: 0.1876 - val_accuracy: 0.9471\n",
      " Learning rate:  0.0001\n",
      "Epoch 30/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0439 - accuracy: 0.9848 - val_loss: 0.1909 - val_accuracy: 0.9484\n",
      " Learning rate:  0.0001\n",
      "Epoch 31/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0426 - accuracy: 0.9852 - val_loss: 0.1955 - val_accuracy: 0.9478\n",
      " Learning rate:  0.0001\n",
      "Epoch 32/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0431 - accuracy: 0.9848 - val_loss: 0.1917 - val_accuracy: 0.9474\n",
      " Learning rate:  0.0001\n",
      "Epoch 33/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0408 - accuracy: 0.9857 - val_loss: 0.1971 - val_accuracy: 0.9488\n",
      " Learning rate:  0.0001\n",
      "Epoch 34/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0403 - accuracy: 0.9863 - val_loss: 0.1992 - val_accuracy: 0.9472\n",
      " Learning rate:  0.0001\n",
      "Epoch 35/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0391 - accuracy: 0.9863 - val_loss: 0.2040 - val_accuracy: 0.9443\n",
      " Learning rate:  0.0001\n",
      "Epoch 36/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0380 - accuracy: 0.9871 - val_loss: 0.2010 - val_accuracy: 0.9478\n",
      " Learning rate:  0.0001\n",
      "Epoch 37/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.2057 - val_accuracy: 0.9482\n",
      " Learning rate:  0.0001\n",
      "Epoch 38/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.2029 - val_accuracy: 0.9474\n",
      " Learning rate:  0.0001\n",
      "Epoch 39/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.2051 - val_accuracy: 0.9466\n",
      " Learning rate:  0.0001\n",
      "Epoch 40/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 0.2078 - val_accuracy: 0.9468\n",
      " Learning rate:  0.0001\n",
      "Epoch 41/100\n",
      "1005/1005 [==============================] - 8s 8ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.2069 - val_accuracy: 0.9475\n",
      "Epoch 00041: early stopping\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"/mnt/vdb/thesis/CustomCNN.Adam.v4.h5\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "# Early Stopping\n",
    "es = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "\n",
    "#learning rate decay\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    batch_size=128, validation_data=(X_val, y_val),\n",
    "                    callbacks=[es, lr_scheduler], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/mnt/vdb/thesis/CustomCNN.Adam.III.V4.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4018/4018 [==============================] - 8s 2ms/step - loss: 0.0201 - accuracy: 0.9945\n",
      "Train loss:  0.02008160762488842\n",
      "Train accuracy:  0.994539737701416\n",
      "----------------------------------------------------------------------\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.2069 - accuracy: 0.9475\n",
      "Val loss:  0.20690956711769104\n",
      "Val accuracy:  0.9474506974220276\n",
      "----------------------------------------------------------------------\n",
      "1340/1340 [==============================] - 3s 2ms/step - loss: 0.2044 - accuracy: 0.9475\n",
      "Test loss:  0.20440642535686493\n",
      "Test accuracy:  0.9475219249725342\n"
     ]
    }
   ],
   "source": [
    "display_model_score(model,\n",
    "    [X_train, y_train],\n",
    "    [X_val, y_val],\n",
    "    [X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     21596\n",
      "           1       0.94      0.95      0.95     21260\n",
      "\n",
      "    accuracy                           0.95     42856\n",
      "   macro avg       0.95      0.95      0.95     42856\n",
      "weighted avg       0.95      0.95      0.95     42856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Markk III\n",
    "y_probas = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_predict = np.where(y_probas > threshold, 1, 0)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-67b1e797cccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_predict' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_predict = np.where(y_probas > threshold, 1, 0)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     22886\n",
      "           1       0.95      0.91      0.93     22400\n",
      "\n",
      "    accuracy                           0.93     45286\n",
      "   macro avg       0.94      0.93      0.93     45286\n",
      "weighted avg       0.93      0.93      0.93     45286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 11/3/2021\n",
    "y_probas = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_predict = np.where(y_probas > threshold, 1, 0)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96     25564\n",
      "           1       0.96      0.95      0.95     25244\n",
      "\n",
      "    accuracy                           0.95     50808\n",
      "   macro avg       0.95      0.95      0.95     50808\n",
      "weighted avg       0.95      0.95      0.95     50808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the best\n",
    "y_probas = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_predict = np.where(y_probas > threshold, 1, 0)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fALQEI9g4Ejn"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF you AveragePooling in any -> didn;t show the good performance so use Maxpooling \n",
    "# 1211 , 512 show the better performance  \n",
    "\n",
    "# 2 CNN layer\n",
    "# 2 Dense layer \n",
    "\n",
    "# Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Gh0Zvl9j4E38"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'layers_by_depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-406262364133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'layers_by_depth'"
     ]
    }
   ],
   "source": [
    "model.layers_by_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CustomDNNModel.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
